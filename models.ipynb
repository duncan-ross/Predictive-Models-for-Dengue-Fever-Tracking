{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"models.ipynb","provenance":[],"collapsed_sections":["e9A7nOxVuo_2","N-AzYEMgnICc","Zx0k2YQ1ztIX","hPMVtKOpzvqM","HcWBOBVU2U41","36uARGqvnQ6c","dRJ_MQMHnT8S","WVDoYzG-nWkt","rPP0uYZnneRW","mhekSHdcsrBW","SYNaT_m_stBj","ejK3Ahmhnh91","j8M53u5-xwFG","2Qu4VxUzxxzu","NMNqw-AwslY8"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8g6FLNz3RMf","executionInfo":{"status":"ok","timestamp":1638470023917,"user_tz":300,"elapsed":31150,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"3a7e185b-8ee8-43d8-de7e-4753a83cc1f1"},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/MyDrive/Undergraduate_Thesis_Duncan/data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/MyDrive/Undergraduate_Thesis_Duncan/data\n"]}]},{"cell_type":"markdown","metadata":{"id":"e9A7nOxVuo_2"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"CIwqCBF92TbG"},"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","plt.rcParams[\"figure.dpi\"] = 144\n","import seaborn as sns\n","import time\n","import itertools\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import r2_score\n","import warnings\n","from datetime import datetime\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uTDNtEer2bMZ"},"source":["import statsmodels.formula.api as smf \n","import statsmodels.api as sm\n","from statsmodels.tools import eval_measures"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N-AzYEMgnICc"},"source":["# Submission Code"]},{"cell_type":"code","metadata":{"id":"tXRS0T5CnGno"},"source":["import os\n","def createSubmission(sj,iq,name):\n","  path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","  name = name + \".csv\"\n","  path = os.path.join(path,name)\n","  df_submission = pd.read_csv(\"submission_format.csv\")\n","  df_submission.total_cases = np.concatenate([sj,iq])\n","  df_submission.to_csv(path,index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4taSxEI2GxK"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"G2OdJzz0zqP1"},"source":["## Normalization function"]},{"cell_type":"code","metadata":{"id":"fQRfvPu_bFQC"},"source":["def normalize(df):\n","    result = df.copy()\n","    norms = [\"reanalysis_air_temp_k\",\"reanalysis_avg_temp_k\",\"reanalysis_dew_point_temp_k\",\"reanalysis_max_air_temp_k\",\"reanalysis_min_air_temp_k\",\"reanalysis_tdtr_k\",\"station_avg_temp_c\",\"station_diur_temp_rng_c\",\"station_max_temp_c\",\"station_min_temp_c\",\"precipitation_amt_mm\",\"reanalysis_precip_amt_kg_per_m2\",\"reanalysis_relative_humidity_percent\",\"reanalysis_sat_precip_amt_mm\",\"reanalysis_specific_humidity_g_per_kg\",\"station_precip_mm\"]\n","    for feature_name in norms:\n","        max_value = df[feature_name].max()\n","        min_value = df[feature_name].min()\n","        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zx0k2YQ1ztIX"},"source":["## Standardization function"]},{"cell_type":"code","metadata":{"id":"8iECVHbZcZYF"},"source":["def standardize(df):\n","  modify = df.copy()\n","  modify = StandardScaler().fit_transform(modify)\n","\n","  result = df.copy()\n","  stans = [\"reanalysis_precip_amt_kg_per_m2\",\"reanalysis_relative_humidity_percent\",\"reanalysis_sat_precip_amt_mm\",\"reanalysis_specific_humidity_g_per_kg\",\"station_precip_mm\"]\n","  for feature_name in stans:\n","    result[feature_name] = modify[feature_name]\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPMVtKOpzvqM"},"source":["## Fix NaN function"]},{"cell_type":"code","metadata":{"id":"Jaz5Um80k0EY"},"source":["def fixNulls(df):\n","  result = df.copy()\n","  for col in df.columns:\n","    if(col != \"city\"):\n","      # first try to fill NaN with mean() values from that week of year across our dataset\n","      # i.e replace null values from a row on week 2 with mean values in week 2 across dataset\n","      df[col] = df.groupby('weekofyear')[col].apply(lambda x: x.fillna(x.mean()))\n","\n","      #if value is still null (because all values for that week are null) replace with column mean\n","      df[col] = df[col].fillna(df[col].mean())\n","  \n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LThykugXcvPp"},"source":["## Correlation Work"]},{"cell_type":"code","metadata":{"id":"aT1sev7pcuX1"},"source":["def check_correlations(df): #train\n","  for colA in df.columns:\n","    for colB in df.columns:\n","      if colA in df and colB in df:\n","        correlation = df[colA].corr(df[colB])\n","        if colA != colB and correlation > .65:\n","            df.drop(colB,axis=1, inplace=True)\n","\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_KX4h9yvmi7a"},"source":["def select_correlation_columns(dfA,dfB): #test data\n","  for col in dfB:\n","    if col not in dfA:\n","      dfB.drop(col,axis=1,inplace=True)\n","  return dfB"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UYjgmw9W2kOB"},"source":["## Preprocess Driver function"]},{"cell_type":"code","metadata":{"id":"VM6NBl5n3h4H"},"source":["def preprocess_input(path,norm,stand,impute):\n","  df = pd.read_csv(path)\n","  if norm:\n","    df = normalize(df)\n","  df.drop('week_start_date', axis=1,inplace=True)\n","\n","  sj = df.loc[df['city'] == 'sj']\n","  iq = df.loc[df['city'] == 'iq']\n","  sj.drop('city', axis=1,inplace=True)\n","  iq.drop('city', axis=1,inplace=True)\n","\n","  if not impute:\n","    sj = fixNulls(sj)\n","    iq = fixNulls(iq)\n","\n","  if stand:\n","    sj = standardize(sj)\n","    iq = standardize(iq)\n","\n","  return sj,iq,df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6at3wUUw3zdL","colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"status":"ok","timestamp":1638470038003,"user_tz":300,"elapsed":1940,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"baddbddf-de97-48fa-d886-93515813cfcf"},"source":["sj_train, iq_train,total = preprocess_input(\"dengue_features_train.csv\",True,False,False)\n","\n","\n","#sj_train, iq_train = check_correlations(sj_train), check_correlations(iq_train)\n","#sj_train.head()\n","total.describe()\n","x = pd.concat([sj_train,iq_train])\n","x.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>weekofyear</th>\n","      <th>ndvi_ne</th>\n","      <th>ndvi_nw</th>\n","      <th>ndvi_se</th>\n","      <th>ndvi_sw</th>\n","      <th>precipitation_amt_mm</th>\n","      <th>reanalysis_air_temp_k</th>\n","      <th>reanalysis_avg_temp_k</th>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <th>reanalysis_tdtr_k</th>\n","      <th>station_avg_temp_c</th>\n","      <th>station_diur_temp_rng_c</th>\n","      <th>station_max_temp_c</th>\n","      <th>station_min_temp_c</th>\n","      <th>station_precip_mm</th>\n","      <th>total_cases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","      <td>1456.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2001.031593</td>\n","      <td>26.503434</td>\n","      <td>0.131372</td>\n","      <td>0.128595</td>\n","      <td>0.203527</td>\n","      <td>0.201866</td>\n","      <td>0.116845</td>\n","      <td>0.537319</td>\n","      <td>0.538990</td>\n","      <td>0.635981</td>\n","      <td>0.347304</td>\n","      <td>0.678160</td>\n","      <td>0.070333</td>\n","      <td>0.597034</td>\n","      <td>0.116845</td>\n","      <td>0.574954</td>\n","      <td>0.241852</td>\n","      <td>0.615638</td>\n","      <td>0.318572</td>\n","      <td>0.371403</td>\n","      <td>0.678631</td>\n","      <td>0.072748</td>\n","      <td>24.675137</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>5.408314</td>\n","      <td>15.019437</td>\n","      <td>0.134417</td>\n","      <td>0.118560</td>\n","      <td>0.073384</td>\n","      <td>0.083452</td>\n","      <td>0.111568</td>\n","      <td>0.179594</td>\n","      <td>0.156578</td>\n","      <td>0.173023</td>\n","      <td>0.199634</td>\n","      <td>0.197053</td>\n","      <td>0.075906</td>\n","      <td>0.174909</td>\n","      <td>0.111568</td>\n","      <td>0.175938</td>\n","      <td>0.241684</td>\n","      <td>0.136108</td>\n","      <td>0.190199</td>\n","      <td>0.126197</td>\n","      <td>0.143918</td>\n","      <td>0.086866</td>\n","      <td>43.596000</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1990.000000</td>\n","      <td>1.000000</td>\n","      <td>-0.406250</td>\n","      <td>-0.456100</td>\n","      <td>-0.015533</td>\n","      <td>-0.063457</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1997.000000</td>\n","      <td>13.750000</td>\n","      <td>0.044025</td>\n","      <td>0.050425</td>\n","      <td>0.155549</td>\n","      <td>0.144639</td>\n","      <td>0.025416</td>\n","      <td>0.400472</td>\n","      <td>0.418667</td>\n","      <td>0.508110</td>\n","      <td>0.197531</td>\n","      <td>0.538462</td>\n","      <td>0.023138</td>\n","      <td>0.476186</td>\n","      <td>0.025416</td>\n","      <td>0.438950</td>\n","      <td>0.066212</td>\n","      <td>0.524316</td>\n","      <td>0.177440</td>\n","      <td>0.283871</td>\n","      <td>0.587156</td>\n","      <td>0.016289</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2002.000000</td>\n","      <td>26.500000</td>\n","      <td>0.105690</td>\n","      <td>0.115133</td>\n","      <td>0.195664</td>\n","      <td>0.187779</td>\n","      <td>0.097721</td>\n","      <td>0.529462</td>\n","      <td>0.546222</td>\n","      <td>0.679319</td>\n","      <td>0.283951</td>\n","      <td>0.715385</td>\n","      <td>0.047853</td>\n","      <td>0.551179</td>\n","      <td>0.097721</td>\n","      <td>0.613852</td>\n","      <td>0.102240</td>\n","      <td>0.639818</td>\n","      <td>0.250317</td>\n","      <td>0.393548</td>\n","      <td>0.688073</td>\n","      <td>0.045003</td>\n","      <td>12.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2005.000000</td>\n","      <td>39.250000</td>\n","      <td>0.230950</td>\n","      <td>0.213429</td>\n","      <td>0.247735</td>\n","      <td>0.246775</td>\n","      <td>0.179333</td>\n","      <td>0.686355</td>\n","      <td>0.661333</td>\n","      <td>0.773601</td>\n","      <td>0.475309</td>\n","      <td>0.846154</td>\n","      <td>0.091499</td>\n","      <td>0.701821</td>\n","      <td>0.179333</td>\n","      <td>0.715657</td>\n","      <td>0.428676</td>\n","      <td>0.715805</td>\n","      <td>0.463799</td>\n","      <td>0.464516</td>\n","      <td>0.788991</td>\n","      <td>0.100359</td>\n","      <td>28.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2010.000000</td>\n","      <td>53.000000</td>\n","      <td>0.508357</td>\n","      <td>0.454429</td>\n","      <td>0.538314</td>\n","      <td>0.546017</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>461.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              year   weekofyear  ...  station_precip_mm  total_cases\n","count  1456.000000  1456.000000  ...        1456.000000  1456.000000\n","mean   2001.031593    26.503434  ...           0.072748    24.675137\n","std       5.408314    15.019437  ...           0.086866    43.596000\n","min    1990.000000     1.000000  ...           0.000000     0.000000\n","25%    1997.000000    13.750000  ...           0.016289     5.000000\n","50%    2002.000000    26.500000  ...           0.045003    12.000000\n","75%    2005.000000    39.250000  ...           0.100359    28.000000\n","max    2010.000000    53.000000  ...           1.000000   461.000000\n","\n","[8 rows x 23 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"xb1eLTuxx3s2"},"source":["\n","x2 = pd.concat([total.groupby('weekofyear').mean().head(),total.groupby('weekofyear').mean().tail()])\n","x2\n","path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","name = \"GROUPED_MEAN.csv\"\n","path = os.path.join(path,name)\n","x2.to_csv(path,index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8pCD2JtpyF8"},"source":["sj_test, iq_test,test = preprocess_input(\"dengue_features_test.csv\",True,False,False)\n","#sj_test, iq_test = select_correlation_columns(sj_train,sj_test), select_correlation_columns(iq_train,iq_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVbVRV881XP9","colab":{"base_uri":"https://localhost:8080/","height":320},"executionInfo":{"status":"ok","timestamp":1638470041356,"user_tz":300,"elapsed":1212,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"928055ac-1ba9-4e14-e17e-71d187500e9d"},"source":["sj_train_2, iq_train_2 ,total_2 = preprocess_input(\"imputed.csv\",True,False,True)\n","sj_train_2.dropna(inplace=True)\n","iq_train_2.dropna(inplace=True)\n","total_2.dropna(inplace=True)\n","total_2.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>weekofyear</th>\n","      <th>ndvi_ne</th>\n","      <th>ndvi_nw</th>\n","      <th>ndvi_se</th>\n","      <th>ndvi_sw</th>\n","      <th>precipitation_amt_mm</th>\n","      <th>reanalysis_air_temp_k</th>\n","      <th>reanalysis_avg_temp_k</th>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <th>reanalysis_tdtr_k</th>\n","      <th>station_avg_temp_c</th>\n","      <th>station_diur_temp_rng_c</th>\n","      <th>station_max_temp_c</th>\n","      <th>station_min_temp_c</th>\n","      <th>station_precip_mm</th>\n","      <th>total_cases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","      <td>1443.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2001.044352</td>\n","      <td>26.538462</td>\n","      <td>0.130925</td>\n","      <td>0.128815</td>\n","      <td>0.203206</td>\n","      <td>0.201841</td>\n","      <td>0.117154</td>\n","      <td>0.537813</td>\n","      <td>0.539514</td>\n","      <td>0.636598</td>\n","      <td>0.347809</td>\n","      <td>0.678357</td>\n","      <td>0.070479</td>\n","      <td>0.597262</td>\n","      <td>0.117154</td>\n","      <td>0.575599</td>\n","      <td>0.242091</td>\n","      <td>0.615897</td>\n","      <td>0.318635</td>\n","      <td>0.371614</td>\n","      <td>0.679166</td>\n","      <td>0.072884</td>\n","      <td>24.613999</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>5.394375</td>\n","      <td>14.906798</td>\n","      <td>0.139828</td>\n","      <td>0.120403</td>\n","      <td>0.074584</td>\n","      <td>0.084180</td>\n","      <td>0.111919</td>\n","      <td>0.180199</td>\n","      <td>0.157005</td>\n","      <td>0.173444</td>\n","      <td>0.199619</td>\n","      <td>0.197532</td>\n","      <td>0.076180</td>\n","      <td>0.175351</td>\n","      <td>0.111919</td>\n","      <td>0.176321</td>\n","      <td>0.241850</td>\n","      <td>0.136723</td>\n","      <td>0.190833</td>\n","      <td>0.126134</td>\n","      <td>0.144422</td>\n","      <td>0.088181</td>\n","      <td>43.713177</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1990.000000</td>\n","      <td>1.000000</td>\n","      <td>-0.406250</td>\n","      <td>-0.456100</td>\n","      <td>-0.015533</td>\n","      <td>-0.063457</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1997.000000</td>\n","      <td>14.000000</td>\n","      <td>0.035450</td>\n","      <td>0.048200</td>\n","      <td>0.153986</td>\n","      <td>0.143071</td>\n","      <td>0.025090</td>\n","      <td>0.399717</td>\n","      <td>0.419556</td>\n","      <td>0.508516</td>\n","      <td>0.197531</td>\n","      <td>0.538462</td>\n","      <td>0.022910</td>\n","      <td>0.475084</td>\n","      <td>0.025090</td>\n","      <td>0.439726</td>\n","      <td>0.066212</td>\n","      <td>0.524126</td>\n","      <td>0.177440</td>\n","      <td>0.283871</td>\n","      <td>0.587156</td>\n","      <td>0.015921</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2002.000000</td>\n","      <td>27.000000</td>\n","      <td>0.116100</td>\n","      <td>0.118525</td>\n","      <td>0.195914</td>\n","      <td>0.188229</td>\n","      <td>0.098157</td>\n","      <td>0.530500</td>\n","      <td>0.547556</td>\n","      <td>0.681265</td>\n","      <td>0.283951</td>\n","      <td>0.715385</td>\n","      <td>0.047853</td>\n","      <td>0.551547</td>\n","      <td>0.098157</td>\n","      <td>0.615158</td>\n","      <td>0.102240</td>\n","      <td>0.639818</td>\n","      <td>0.252218</td>\n","      <td>0.393548</td>\n","      <td>0.688073</td>\n","      <td>0.044174</td>\n","      <td>12.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2005.000000</td>\n","      <td>39.000000</td>\n","      <td>0.233300</td>\n","      <td>0.214008</td>\n","      <td>0.248792</td>\n","      <td>0.246964</td>\n","      <td>0.179813</td>\n","      <td>0.687630</td>\n","      <td>0.661333</td>\n","      <td>0.774128</td>\n","      <td>0.475309</td>\n","      <td>0.846154</td>\n","      <td>0.091762</td>\n","      <td>0.701078</td>\n","      <td>0.179813</td>\n","      <td>0.716269</td>\n","      <td>0.427945</td>\n","      <td>0.718845</td>\n","      <td>0.454373</td>\n","      <td>0.464516</td>\n","      <td>0.788991</td>\n","      <td>0.099577</td>\n","      <td>28.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2010.000000</td>\n","      <td>52.000000</td>\n","      <td>0.508357</td>\n","      <td>0.454429</td>\n","      <td>0.538314</td>\n","      <td>0.546017</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>461.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              year   weekofyear  ...  station_precip_mm  total_cases\n","count  1443.000000  1443.000000  ...        1443.000000  1443.000000\n","mean   2001.044352    26.538462  ...           0.072884    24.613999\n","std       5.394375    14.906798  ...           0.088181    43.713177\n","min    1990.000000     1.000000  ...           0.000000     0.000000\n","25%    1997.000000    14.000000  ...           0.015921     5.000000\n","50%    2002.000000    27.000000  ...           0.044174    12.000000\n","75%    2005.000000    39.000000  ...           0.099577    28.000000\n","max    2010.000000    52.000000  ...           1.000000   461.000000\n","\n","[8 rows x 23 columns]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"Qy2ciikEic8i","executionInfo":{"status":"ok","timestamp":1638470041878,"user_tz":300,"elapsed":526,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"666f03f3-6abd-4ee6-a4a1-01a8dac59a17"},"source":["sj_train_2.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>weekofyear</th>\n","      <th>ndvi_ne</th>\n","      <th>ndvi_nw</th>\n","      <th>ndvi_se</th>\n","      <th>ndvi_sw</th>\n","      <th>precipitation_amt_mm</th>\n","      <th>reanalysis_air_temp_k</th>\n","      <th>reanalysis_avg_temp_k</th>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <th>reanalysis_tdtr_k</th>\n","      <th>station_avg_temp_c</th>\n","      <th>station_diur_temp_rng_c</th>\n","      <th>station_max_temp_c</th>\n","      <th>station_min_temp_c</th>\n","      <th>station_precip_mm</th>\n","      <th>total_cases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.000000</td>\n","      <td>927.00000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1998.851133</td>\n","      <td>26.559871</td>\n","      <td>0.056652</td>\n","      <td>0.067419</td>\n","      <td>0.176903</td>\n","      <td>0.165384</td>\n","      <td>0.090811</td>\n","      <td>0.599211</td>\n","      <td>0.546108</td>\n","      <td>0.621208</td>\n","      <td>0.222455</td>\n","      <td>0.800473</td>\n","      <td>0.053501</td>\n","      <td>0.509041</td>\n","      <td>0.090811</td>\n","      <td>0.553554</td>\n","      <td>0.079031</td>\n","      <td>0.596892</td>\n","      <td>0.197753</td>\n","      <td>0.316595</td>\n","      <td>0.725265</td>\n","      <td>0.049409</td>\n","      <td>34.08630</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>5.207721</td>\n","      <td>14.911562</td>\n","      <td>0.106420</td>\n","      <td>0.093514</td>\n","      <td>0.058276</td>\n","      <td>0.056444</td>\n","      <td>0.114199</td>\n","      <td>0.163355</td>\n","      <td>0.151599</td>\n","      <td>0.178273</td>\n","      <td>0.077637</td>\n","      <td>0.099561</td>\n","      <td>0.062524</td>\n","      <td>0.083060</td>\n","      <td>0.114199</td>\n","      <td>0.178477</td>\n","      <td>0.034051</td>\n","      <td>0.150603</td>\n","      <td>0.074245</td>\n","      <td>0.110760</td>\n","      <td>0.138138</td>\n","      <td>0.054028</td>\n","      <td>51.57143</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1990.000000</td>\n","      <td>1.000000</td>\n","      <td>-0.406250</td>\n","      <td>-0.456100</td>\n","      <td>-0.015533</td>\n","      <td>-0.063457</td>\n","      <td>0.000000</td>\n","      <td>0.172238</td>\n","      <td>0.152000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.438462</td>\n","      <td>0.000000</td>\n","      <td>0.219205</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.153495</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.284404</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1994.000000</td>\n","      <td>14.000000</td>\n","      <td>0.004133</td>\n","      <td>0.016550</td>\n","      <td>0.138729</td>\n","      <td>0.128111</td>\n","      <td>0.000000</td>\n","      <td>0.471010</td>\n","      <td>0.425333</td>\n","      <td>0.477940</td>\n","      <td>0.160494</td>\n","      <td>0.723077</td>\n","      <td>0.019018</td>\n","      <td>0.452180</td>\n","      <td>0.000000</td>\n","      <td>0.403545</td>\n","      <td>0.054528</td>\n","      <td>0.472644</td>\n","      <td>0.148289</td>\n","      <td>0.251613</td>\n","      <td>0.642202</td>\n","      <td>0.012608</td>\n","      <td>9.00000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1999.000000</td>\n","      <td>27.000000</td>\n","      <td>0.056800</td>\n","      <td>0.068650</td>\n","      <td>0.176786</td>\n","      <td>0.165729</td>\n","      <td>0.053251</td>\n","      <td>0.612653</td>\n","      <td>0.559111</td>\n","      <td>0.661314</td>\n","      <td>0.228395</td>\n","      <td>0.815385</td>\n","      <td>0.037511</td>\n","      <td>0.511513</td>\n","      <td>0.053251</td>\n","      <td>0.587063</td>\n","      <td>0.074976</td>\n","      <td>0.621581</td>\n","      <td>0.197719</td>\n","      <td>0.322581</td>\n","      <td>0.743119</td>\n","      <td>0.032763</td>\n","      <td>19.00000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2003.000000</td>\n","      <td>39.000000</td>\n","      <td>0.112050</td>\n","      <td>0.115200</td>\n","      <td>0.212386</td>\n","      <td>0.202555</td>\n","      <td>0.133589</td>\n","      <td>0.727101</td>\n","      <td>0.664444</td>\n","      <td>0.769505</td>\n","      <td>0.283951</td>\n","      <td>0.884615</td>\n","      <td>0.064943</td>\n","      <td>0.567592</td>\n","      <td>0.133589</td>\n","      <td>0.703038</td>\n","      <td>0.098345</td>\n","      <td>0.722644</td>\n","      <td>0.244613</td>\n","      <td>0.393548</td>\n","      <td>0.844037</td>\n","      <td>0.065433</td>\n","      <td>37.00000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2008.000000</td>\n","      <td>52.000000</td>\n","      <td>0.493400</td>\n","      <td>0.437100</td>\n","      <td>0.393129</td>\n","      <td>0.381420</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.904889</td>\n","      <td>0.925710</td>\n","      <td>0.401235</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.729703</td>\n","      <td>1.000000</td>\n","      <td>0.883208</td>\n","      <td>0.209348</td>\n","      <td>0.922492</td>\n","      <td>0.477820</td>\n","      <td>0.574194</td>\n","      <td>1.000000</td>\n","      <td>0.563041</td>\n","      <td>461.00000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              year  weekofyear  ...  station_precip_mm  total_cases\n","count   927.000000  927.000000  ...         927.000000    927.00000\n","mean   1998.851133   26.559871  ...           0.049409     34.08630\n","std       5.207721   14.911562  ...           0.054028     51.57143\n","min    1990.000000    1.000000  ...           0.000000      0.00000\n","25%    1994.000000   14.000000  ...           0.012608      9.00000\n","50%    1999.000000   27.000000  ...           0.032763     19.00000\n","75%    2003.000000   39.000000  ...           0.065433     37.00000\n","max    2008.000000   52.000000  ...           0.563041    461.00000\n","\n","[8 rows x 23 columns]"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"7KtVYkskifKX","executionInfo":{"status":"ok","timestamp":1638470041882,"user_tz":300,"elapsed":11,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"7d4a8ee6-8e62-45bf-d8de-1e5cb5584ee6"},"source":["iq_train_2.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>weekofyear</th>\n","      <th>ndvi_ne</th>\n","      <th>ndvi_nw</th>\n","      <th>ndvi_se</th>\n","      <th>ndvi_sw</th>\n","      <th>precipitation_amt_mm</th>\n","      <th>reanalysis_air_temp_k</th>\n","      <th>reanalysis_avg_temp_k</th>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <th>reanalysis_tdtr_k</th>\n","      <th>station_avg_temp_c</th>\n","      <th>station_diur_temp_rng_c</th>\n","      <th>station_max_temp_c</th>\n","      <th>station_min_temp_c</th>\n","      <th>station_precip_mm</th>\n","      <th>total_cases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","      <td>516.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>2004.984496</td>\n","      <td>26.500000</td>\n","      <td>0.264358</td>\n","      <td>0.239114</td>\n","      <td>0.250461</td>\n","      <td>0.267336</td>\n","      <td>0.164480</td>\n","      <td>0.427512</td>\n","      <td>0.527668</td>\n","      <td>0.664248</td>\n","      <td>0.573009</td>\n","      <td>0.458974</td>\n","      <td>0.100981</td>\n","      <td>0.755752</td>\n","      <td>0.164480</td>\n","      <td>0.615204</td>\n","      <td>0.535029</td>\n","      <td>0.650039</td>\n","      <td>0.535801</td>\n","      <td>0.470455</td>\n","      <td>0.596348</td>\n","      <td>0.115056</td>\n","      <td>7.596899</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.915601</td>\n","      <td>14.912626</td>\n","      <td>0.081325</td>\n","      <td>0.076767</td>\n","      <td>0.077372</td>\n","      <td>0.086155</td>\n","      <td>0.090166</td>\n","      <td>0.154806</td>\n","      <td>0.165769</td>\n","      <td>0.160918</td>\n","      <td>0.147098</td>\n","      <td>0.127928</td>\n","      <td>0.088145</td>\n","      <td>0.185776</td>\n","      <td>0.090166</td>\n","      <td>0.165312</td>\n","      <td>0.166891</td>\n","      <td>0.098693</td>\n","      <td>0.136020</td>\n","      <td>0.085157</td>\n","      <td>0.115729</td>\n","      <td>0.117261</td>\n","      <td>10.796813</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>2000.000000</td>\n","      <td>1.000000</td>\n","      <td>0.061729</td>\n","      <td>0.035860</td>\n","      <td>0.029880</td>\n","      <td>0.064183</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.050608</td>\n","      <td>0.135802</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.045247</td>\n","      <td>0.160662</td>\n","      <td>0.000000</td>\n","      <td>0.059569</td>\n","      <td>0.219355</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2002.000000</td>\n","      <td>14.000000</td>\n","      <td>0.200150</td>\n","      <td>0.180260</td>\n","      <td>0.194748</td>\n","      <td>0.205246</td>\n","      <td>0.100115</td>\n","      <td>0.324788</td>\n","      <td>0.414222</td>\n","      <td>0.562165</td>\n","      <td>0.456790</td>\n","      <td>0.390385</td>\n","      <td>0.042182</td>\n","      <td>0.649339</td>\n","      <td>0.100115</td>\n","      <td>0.501633</td>\n","      <td>0.409932</td>\n","      <td>0.595080</td>\n","      <td>0.441065</td>\n","      <td>0.419355</td>\n","      <td>0.541284</td>\n","      <td>0.031290</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>2005.000000</td>\n","      <td>26.500000</td>\n","      <td>0.265379</td>\n","      <td>0.233593</td>\n","      <td>0.250129</td>\n","      <td>0.262429</td>\n","      <td>0.154813</td>\n","      <td>0.421341</td>\n","      <td>0.526222</td>\n","      <td>0.705028</td>\n","      <td>0.570988</td>\n","      <td>0.473077</td>\n","      <td>0.081402</td>\n","      <td>0.811555</td>\n","      <td>0.154813</td>\n","      <td>0.653218</td>\n","      <td>0.518500</td>\n","      <td>0.659574</td>\n","      <td>0.539766</td>\n","      <td>0.470968</td>\n","      <td>0.610092</td>\n","      <td>0.083011</td>\n","      <td>5.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>2007.000000</td>\n","      <td>39.000000</td>\n","      <td>0.320246</td>\n","      <td>0.293989</td>\n","      <td>0.303396</td>\n","      <td>0.325432</td>\n","      <td>0.219553</td>\n","      <td>0.530595</td>\n","      <td>0.650889</td>\n","      <td>0.784104</td>\n","      <td>0.672840</td>\n","      <td>0.561538</td>\n","      <td>0.124579</td>\n","      <td>0.900887</td>\n","      <td>0.219553</td>\n","      <td>0.739178</td>\n","      <td>0.658228</td>\n","      <td>0.712766</td>\n","      <td>0.632034</td>\n","      <td>0.524194</td>\n","      <td>0.669725</td>\n","      <td>0.158200</td>\n","      <td>9.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2010.000000</td>\n","      <td>52.000000</td>\n","      <td>0.508357</td>\n","      <td>0.454429</td>\n","      <td>0.538314</td>\n","      <td>0.546017</td>\n","      <td>0.539759</td>\n","      <td>0.925590</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.700000</td>\n","      <td>0.634584</td>\n","      <td>1.000000</td>\n","      <td>0.539759</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.871560</td>\n","      <td>1.000000</td>\n","      <td>116.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              year  weekofyear  ...  station_precip_mm  total_cases\n","count   516.000000  516.000000  ...         516.000000   516.000000\n","mean   2004.984496   26.500000  ...           0.115056     7.596899\n","std       2.915601   14.912626  ...           0.117261    10.796813\n","min    2000.000000    1.000000  ...           0.000000     0.000000\n","25%    2002.000000   14.000000  ...           0.031290     1.000000\n","50%    2005.000000   26.500000  ...           0.083011     5.000000\n","75%    2007.000000   39.000000  ...           0.158200     9.000000\n","max    2010.000000   52.000000  ...           1.000000   116.000000\n","\n","[8 rows x 23 columns]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"zUUSRSTkIZPH"},"source":["  #EXPORT SUMMARY DATA TO CSV\n","  path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","  name = \"SUMMARY_DATA.csv\"\n","  path = os.path.join(path,name)\n","  total.describe().to_csv(path,index=True)\n","  \n","  name = \"SUMMARY_DATA_IMPUTED.csv\"\n","  path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","  path = os.path.join(path,name)\n","  total_2.describe().to_csv(path,index=True)\n","\n","  name = \"SUMMARY_DATA_GROUP_AVG .csv\"\n","  path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","  path = os.path.join(path,name)\n","  x.describe().to_csv(path,index=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iVUse_n0rWW"},"source":["reduced_train_sj = sj_train[['year', 'weekofyear', 'ndvi_se','total_cases']].copy()\n","reduced_train_iq = iq_train[['year', 'weekofyear', 'ndvi_se','total_cases']].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmsV731X2ezZ"},"source":["reduced_train_sj_2 = sj_train_2[['year', 'weekofyear', 'ndvi_se','total_cases']].copy()\n","reduced_train_iq_2 = iq_train_2[['year', 'weekofyear', 'ndvi_se','total_cases']].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIPhcXC8fla6"},"source":["reduced_test_sj = sj_test[['year', 'weekofyear', 'ndvi_se']].copy()\n","reduced_test_iq = iq_test[['year', 'weekofyear', 'ndvi_se']].copy()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcWBOBVU2U41"},"source":["# Model 1 -- Negative Binomial\n"]},{"cell_type":"markdown","metadata":{"id":"36uARGqvnQ6c"},"source":["## Find best equation for Model 1\n"]},{"cell_type":"code","metadata":{"id":"P2xQ4tu1HSMX"},"source":["def bestModel(X_train, X_test):\n","  eq = \"total_cases ~ 1\"\n","  bestScore = 1000000\n","  bestModel = None\n","  usedCol = ['total_cases']\n","  \n","\n","  for x in range(len(X_train.columns)):\n","    testScore = bestScore\n","    curr_eq = \"\"\n","    testModel = None\n","\n","    for col in X_train.columns:\n","      if col in usedCol:\n","        continue\n","      test_eq = eq + \" + \" + col\n","      model = smf.glm(formula = test_eq, data=X_train, family=sm.families.NegativeBinomial()).fit()\n","      predictions = model.predict(X_test).astype(int)\n","      score = eval_measures.meanabs(predictions, X_test.total_cases)\n","      if score < testScore:\n","        testScore = score\n","        curr_eq = test_eq\n","        testModel = model\n","\n","    if testScore < bestScore:\n","      bestScore = testScore\n","      eq = curr_eq\n","      bestModel = testModel\n","      usedCol.append(col)\n","    else:\n","      break\n","  \n","  return eq, bestScore, bestModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iieqh0AB6Fc"},"source":["def saturatedModel(X_train, X_test):\n","  eq = \"total_cases ~ 1\"\n","  usedCol = ['total_cases']\n","\n","  for col in X_train.columns:\n","      if col not in usedCol:\n","        eq = eq + \" + \" + col\n","        usedCol.append(col)\n","  \n","  model = smf.glm(formula = eq, data=X_train, family=sm.families.NegativeBinomial()).fit()\n","  predictions = model.predict(X_test).astype(int)\n","  score = eval_measures.meanabs(predictions, X_test.total_cases)\n","\n","  return score, model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dRJ_MQMHnT8S"},"source":["## Fit for SJ Data"]},{"cell_type":"code","metadata":{"id":"x0dycdOfJWlN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638127063358,"user_tz":300,"elapsed":10052,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"142e0b4a-4ac0-4461-d660-43e8a49a43cb"},"source":["X_train, X_test = train_test_split(sj_train, test_size=0.33, random_state=42)\n","sj_eq, sj_score, sj_model = bestModel(X_train, X_test)\n","print(sj_score)\n","print(sj_eq)\n","sj_model.summary()\n","sj_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["23.540453074433657\n","total_cases ~ 1 + weekofyear + year + reanalysis_max_air_temp_k + station_avg_temp_c + ndvi_ne + ndvi_sw + reanalysis_air_temp_k + station_min_temp_c + reanalysis_avg_temp_k + station_diur_temp_rng_c\n"]},{"output_type":"execute_result","data":{"text/plain":["5489.00847561913"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vxsXRkMkiGTf","executionInfo":{"status":"ok","timestamp":1638127070461,"user_tz":300,"elapsed":7108,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"2168131d-3e06-434d-dbaf-ffa046fc30a0"},"source":["X_train, X_test = train_test_split(sj_train_2, test_size=0.33, random_state=42)\n","sj_eq, sj_score, sj_model = bestModel(X_train, X_test)\n","print(sj_score)\n","print(sj_eq)\n","sj_model.summary()\n","sj_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["21.81045751633987\n","total_cases ~ 1 + weekofyear + year + reanalysis_max_air_temp_k + station_avg_temp_c + ndvi_ne + ndvi_se + station_max_temp_c + reanalysis_relative_humidity_percent\n"]},{"output_type":"execute_result","data":{"text/plain":["5477.830369213732"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"WVDoYzG-nWkt"},"source":["## Fit for IQ Data"]},{"cell_type":"code","metadata":{"id":"3L_idGNDLWZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638127072129,"user_tz":300,"elapsed":1679,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"50c87253-b2b4-4fc6-e571-d19827d6ca8f"},"source":["X_train, X_test = train_test_split(iq_train, test_size=0.33, random_state=42)\n","iq_eq, iq_score, iq_model = bestModel(X_train, X_test)\n","print(iq_score)\n","print(iq_eq)\n","iq_model.summary()\n","iq_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6.017441860465116\n","total_cases ~ 1 + year + reanalysis_tdtr_k + precipitation_amt_mm\n"]},{"output_type":"execute_result","data":{"text/plain":["2143.3666125592163"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSTmr73bi7Iz","executionInfo":{"status":"ok","timestamp":1638127075956,"user_tz":300,"elapsed":3831,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"f4fda6c8-558e-41ff-d4b6-7e84d20a28ec"},"source":["X_train, X_test = train_test_split(iq_train_2, test_size=0.33, random_state=42)\n","iq_eq, iq_score, iq_model = bestModel(X_train, X_test)\n","print(iq_score)\n","print(iq_eq)\n","iq_model.summary()\n","iq_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5.678362573099415\n","total_cases ~ 1 + year + reanalysis_relative_humidity_percent + reanalysis_precip_amt_kg_per_m2 + ndvi_ne + ndvi_se + station_diur_temp_rng_c\n"]},{"output_type":"execute_result","data":{"text/plain":["2129.9606841252794"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"aZHN7SIbChIH"},"source":["## Fits for submission"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZNxkz1pCgQr","executionInfo":{"status":"ok","timestamp":1638128149521,"user_tz":300,"elapsed":278,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"fc134df2-e8ae-4fbf-c2b8-a9fa925d7b21"},"source":["#SJ IMPUTED\n","X_train, X_test = train_test_split(sj_train_2, test_size=0.33, random_state=42)\n","sj_score, sj_model = saturatedModel(X_train, X_test)\n","print(\"MAE\",sj_score)\n","sj_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE 24.598705501618124\n"]},{"output_type":"execute_result","data":{"text/plain":["5491.910529928943"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nM2WDDlXDBuV","executionInfo":{"status":"ok","timestamp":1638128236583,"user_tz":300,"elapsed":301,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"9721b62b-0495-4a09-d206-15effbcb2269"},"source":["#SJ GROUPED\n","X_train, X_test = train_test_split(sj_train, test_size=0.33, random_state=42)\n","sj_score, sj_model = saturatedModel(X_train, X_test)\n","print(\"MAE\",sj_score)\n","sj_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE 24.598705501618124\n"]},{"output_type":"execute_result","data":{"text/plain":["5491.910529928943"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6cRus79DCEi","executionInfo":{"status":"ok","timestamp":1638128261164,"user_tz":300,"elapsed":303,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"4e5670fd-9c4c-4ee2-ae17-f1cd08771166"},"source":["#IQ IMPUTED\n","X_train, X_test = train_test_split(iq_train_2, test_size=0.33, random_state=42)\n","iq_score, iq_model = saturatedModel(X_train, X_test)\n","print(\"MAE\",iq_score)\n","iq_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE 6.678362573099415\n"]},{"output_type":"execute_result","data":{"text/plain":["2093.2159224794023"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCD8JXhBDCac","executionInfo":{"status":"ok","timestamp":1638128266040,"user_tz":300,"elapsed":263,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"6fa1b1d6-cb7f-485c-81e5-2d477a26f00e"},"source":["#IQ GROUPED\n","X_train, X_test = train_test_split(iq_train, test_size=0.33, random_state=42)\n","iq_score, iq_model = saturatedModel(X_train, X_test)\n","print(\"MAE\",iq_score)\n","iq_model.aic"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE 6.616279069767442\n"]},{"output_type":"execute_result","data":{"text/plain":["2111.5963475455246"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","metadata":{"id":"id3jWTW7L1N_"},"source":["## Submit Model 1"]},{"cell_type":"code","metadata":{"id":"9-P_0qeLL3Kh","colab":{"base_uri":"https://localhost:8080/","height":540},"executionInfo":{"status":"error","timestamp":1638127087734,"user_tz":300,"elapsed":11780,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"baa4f2ec-1160-4bff-88cb-a1625dce5a32"},"source":["now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission1_nb_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_model.predict(sj_test).astype(int),iq_model.predict(iq_test).astype(int),name)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-45a0c478ac3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdt_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d-%m-%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter change title: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"submission1_nb_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"rPP0uYZnneRW"},"source":["# Model 2 -- DNN"]},{"cell_type":"code","metadata":{"id":"sApKbKOnnmeo"},"source":["import tensorflow as tf\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers.experimental import preprocessing"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oj3-S7agsian"},"source":["## Model Layers and set up"]},{"cell_type":"code","metadata":{"id":"ddnlCNEtnmb5"},"source":["def build_and_compile_model(norm, n, l,shape):\n","  model = None\n","  if l is 2:\n","    model = keras.Sequential([\n","        tf.keras.layers.Input(shape=shape),\n","        tf.keras.layers.Dense(n, activation='relu'),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(n/2, activation='relu'),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(1)\n","      ])\n","  else:\n","    model = keras.Sequential([\n","        tf.keras.layers.Input(shape=shape),\n","        tf.keras.layers.Dense(n, activation='relu'),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(n/2, activation='relu'),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(n/4, activation='relu'),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(1)\n","      ])\n","\n","  model.compile(loss='mean_absolute_error',\n","                optimizer=tf.keras.optimizers.Adam(0.001))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcA8U3lzsmCc"},"source":["## Model building"]},{"cell_type":"code","metadata":{"id":"LZCuNFx4nmZM"},"source":["def build_DNN_model(df):\n","  X = df.copy()\n","  y = X.pop('total_cases')\n","  \n","  normalizer = preprocessing.Normalization(axis=-1)\n","  normalizer.adapt(np.array(X))\n","  params = [64,128,256]\n","  layers = [2]\n","  bestModel = None\n","  bestScore = 1000000\n","  \n","  for l in layers:\n","   for n in params:\n","     X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.85,random_state=42)\n","     dnn_model = build_and_compile_model(normalizer,n,l,X_train.shape[-1])\n","     reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"mae\", factor=0.8, patience=3, min_lr=1e-6, verbose=1,\n","                                                      mode=\"max\")\n","     %%time\n","     history = dnn_model.fit(X_train, y_train, validation_split=0.15, verbose=1, epochs=40,steps_per_epoch=200,callbacks=[reduce_lr])\n","     score = dnn_model.evaluate(X_test, y_test, verbose=1)\n","     \n","     if(score < bestScore):\n","      bestModel = dnn_model\n","      bestScore = score\n","      bestParams = [n,l]\n","\n","  \n","  return bestScore, bestModel, bestParams"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M300fTTLsoW5"},"source":["## Fit for SJ"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tAk9T50EeJy","executionInfo":{"status":"ok","timestamp":1637964706824,"user_tz":300,"elapsed":56258,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"eb4887b0-ecf1-40d8-f8aa-075bb203a7c7"},"source":["sj_dnn_score, sj_dnn_model, sj_dnn_params = build_DNN_model(sj_train)\n","print(sj_dnn_score)\n","print(\"best n: \" + str(sj_dnn_params[0]))\n","print(\"best l: \" + str(sj_dnn_params[1]))\n","sj_dnn_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 8.34 µs\n","Epoch 1/40\n","173/200 [========================>.....] - ETA: 0s - loss: 71.1321WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 2ms/step - loss: 68.8525 - val_loss: 24.3791 - lr: 0.0010\n","Epoch 2/40\n","193/200 [===========================>..] - ETA: 0s - loss: 33.8127WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 34.1994 - val_loss: 17.3802 - lr: 0.0010\n","Epoch 3/40\n","185/200 [==========================>...] - ETA: 0s - loss: 26.9770WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2113 - val_loss: 17.5576 - lr: 0.0010\n","Epoch 4/40\n","189/200 [===========================>..] - ETA: 0s - loss: 31.2151WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 30.7099 - val_loss: 17.6155 - lr: 0.0010\n","Epoch 5/40\n","188/200 [===========================>..] - ETA: 0s - loss: 28.9979WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.3357 - val_loss: 17.4087 - lr: 0.0010\n","Epoch 6/40\n","183/200 [==========================>...] - ETA: 0s - loss: 28.0342WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.5763 - val_loss: 17.7070 - lr: 0.0010\n","Epoch 7/40\n","191/200 [===========================>..] - ETA: 0s - loss: 28.5947WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.8721 - val_loss: 16.9590 - lr: 0.0010\n","Epoch 8/40\n","181/200 [==========================>...] - ETA: 0s - loss: 28.2810WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.1643 - val_loss: 17.7189 - lr: 0.0010\n","Epoch 9/40\n","188/200 [===========================>..] - ETA: 0s - loss: 26.3464WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.0229 - val_loss: 17.8399 - lr: 0.0010\n","Epoch 10/40\n","187/200 [===========================>..] - ETA: 0s - loss: 28.0936WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8798 - val_loss: 17.0840 - lr: 0.0010\n","Epoch 11/40\n","199/200 [============================>.] - ETA: 0s - loss: 28.0245WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.0835 - val_loss: 16.9678 - lr: 0.0010\n","Epoch 12/40\n","200/200 [==============================] - ETA: 0s - loss: 29.5397WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.5397 - val_loss: 16.9909 - lr: 0.0010\n","Epoch 13/40\n","188/200 [===========================>..] - ETA: 0s - loss: 26.3272WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6924 - val_loss: 16.8254 - lr: 0.0010\n","Epoch 14/40\n","194/200 [============================>.] - ETA: 0s - loss: 28.1651WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9646 - val_loss: 17.2816 - lr: 0.0010\n","Epoch 15/40\n","195/200 [============================>.] - ETA: 0s - loss: 27.4673WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4101 - val_loss: 16.7015 - lr: 0.0010\n","Epoch 16/40\n","188/200 [===========================>..] - ETA: 0s - loss: 27.0544WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4715 - val_loss: 18.5462 - lr: 0.0010\n","Epoch 17/40\n","167/200 [========================>.....] - ETA: 0s - loss: 27.0633WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4508 - val_loss: 17.0567 - lr: 0.0010\n","Epoch 18/40\n","191/200 [===========================>..] - ETA: 0s - loss: 27.2206WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4165 - val_loss: 16.6726 - lr: 0.0010\n","Epoch 19/40\n","195/200 [============================>.] - ETA: 0s - loss: 27.3803WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1354 - val_loss: 16.5749 - lr: 0.0010\n","Epoch 20/40\n","194/200 [============================>.] - ETA: 0s - loss: 26.9910WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2496 - val_loss: 16.2917 - lr: 0.0010\n","Epoch 21/40\n","200/200 [==============================] - ETA: 0s - loss: 26.3536WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3536 - val_loss: 16.8363 - lr: 0.0010\n","Epoch 22/40\n","167/200 [========================>.....] - ETA: 0s - loss: 28.1164WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8947 - val_loss: 17.9983 - lr: 0.0010\n","Epoch 23/40\n","174/200 [=========================>....] - ETA: 0s - loss: 26.4716WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6697 - val_loss: 16.4980 - lr: 0.0010\n","Epoch 24/40\n","182/200 [==========================>...] - ETA: 0s - loss: 29.1372WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.3121 - val_loss: 17.4814 - lr: 0.0010\n","Epoch 25/40\n","165/200 [=======================>......] - ETA: 0s - loss: 25.8609WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.5157 - val_loss: 16.3968 - lr: 0.0010\n","Epoch 26/40\n","194/200 [============================>.] - ETA: 0s - loss: 28.3435WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2713 - val_loss: 17.2382 - lr: 0.0010\n","Epoch 27/40\n","186/200 [==========================>...] - ETA: 0s - loss: 26.0366WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.2462 - val_loss: 16.5256 - lr: 0.0010\n","Epoch 28/40\n","193/200 [===========================>..] - ETA: 0s - loss: 26.1762WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3046 - val_loss: 16.8845 - lr: 0.0010\n","Epoch 29/40\n","197/200 [============================>.] - ETA: 0s - loss: 28.1712WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2472 - val_loss: 16.5611 - lr: 0.0010\n","Epoch 30/40\n","184/200 [==========================>...] - ETA: 0s - loss: 27.5526WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.0876 - val_loss: 17.0126 - lr: 0.0010\n","Epoch 31/40\n","165/200 [=======================>......] - ETA: 0s - loss: 24.6905WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.4781 - val_loss: 16.1593 - lr: 0.0010\n","Epoch 32/40\n","169/200 [========================>.....] - ETA: 0s - loss: 25.7379WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1781 - val_loss: 17.4217 - lr: 0.0010\n","Epoch 33/40\n","183/200 [==========================>...] - ETA: 0s - loss: 28.0113WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.0317 - val_loss: 16.8346 - lr: 0.0010\n","Epoch 34/40\n","128/200 [==================>...........] - ETA: 0s - loss: 24.4514WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.3216 - val_loss: 16.2934 - lr: 0.0010\n","5/5 [==============================] - 0s 3ms/step - loss: 18.5226\n","CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n","Wall time: 7.63 µs\n","Epoch 1/40\n","189/200 [===========================>..] - ETA: 0s - loss: 63.2980WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 3ms/step - loss: 61.7846 - val_loss: 27.1884 - lr: 0.0010\n","Epoch 2/40\n","172/200 [========================>.....] - ETA: 0s - loss: 31.5017WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 31.3186 - val_loss: 17.1685 - lr: 0.0010\n","Epoch 3/40\n","191/200 [===========================>..] - ETA: 0s - loss: 28.1147WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.1114 - val_loss: 17.2866 - lr: 0.0010\n","Epoch 4/40\n","178/200 [=========================>....] - ETA: 0s - loss: 28.3395WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8315 - val_loss: 17.4076 - lr: 0.0010\n","Epoch 5/40\n","184/200 [==========================>...] - ETA: 0s - loss: 28.5161WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.4023 - val_loss: 17.1453 - lr: 0.0010\n","Epoch 6/40\n","177/200 [=========================>....] - ETA: 0s - loss: 27.6534WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4831 - val_loss: 17.0782 - lr: 0.0010\n","Epoch 7/40\n","187/200 [===========================>..] - ETA: 0s - loss: 26.9656WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6176 - val_loss: 17.3050 - lr: 0.0010\n","Epoch 8/40\n","179/200 [=========================>....] - ETA: 0s - loss: 28.0488WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2845 - val_loss: 17.1850 - lr: 0.0010\n","Epoch 9/40\n","182/200 [==========================>...] - ETA: 0s - loss: 28.6645WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.8108 - val_loss: 16.9943 - lr: 0.0010\n","Epoch 10/40\n","178/200 [=========================>....] - ETA: 0s - loss: 28.7698WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.1365 - val_loss: 17.4134 - lr: 0.0010\n","Epoch 11/40\n","185/200 [==========================>...] - ETA: 0s - loss: 27.8418WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4261 - val_loss: 16.9168 - lr: 0.0010\n","Epoch 12/40\n","190/200 [===========================>..] - ETA: 0s - loss: 26.6840WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0060 - val_loss: 16.6914 - lr: 0.0010\n","Epoch 13/40\n","186/200 [==========================>...] - ETA: 0s - loss: 26.7576WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.2523 - val_loss: 16.8234 - lr: 0.0010\n","Epoch 14/40\n","180/200 [==========================>...] - ETA: 0s - loss: 28.5393WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.8572 - val_loss: 16.7331 - lr: 0.0010\n","Epoch 15/40\n","182/200 [==========================>...] - ETA: 0s - loss: 28.4131WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.6574 - val_loss: 16.7490 - lr: 0.0010\n","Epoch 16/40\n","185/200 [==========================>...] - ETA: 0s - loss: 27.8681WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8555 - val_loss: 16.6663 - lr: 0.0010\n","Epoch 17/40\n","188/200 [===========================>..] - ETA: 0s - loss: 27.7238WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.7388 - val_loss: 16.6609 - lr: 0.0010\n","Epoch 18/40\n","173/200 [========================>.....] - ETA: 0s - loss: 26.0915WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3802 - val_loss: 18.0803 - lr: 0.0010\n","Epoch 19/40\n","193/200 [===========================>..] - ETA: 0s - loss: 27.4864WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0430 - val_loss: 18.6375 - lr: 0.0010\n","Epoch 20/40\n","175/200 [=========================>....] - ETA: 0s - loss: 26.8306WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.2970 - val_loss: 16.2864 - lr: 0.0010\n","Epoch 21/40\n","184/200 [==========================>...] - ETA: 0s - loss: 28.8615WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.3259 - val_loss: 17.3101 - lr: 0.0010\n","Epoch 22/40\n","181/200 [==========================>...] - ETA: 0s - loss: 26.5832WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1010 - val_loss: 16.8168 - lr: 0.0010\n","Epoch 23/40\n","179/200 [=========================>....] - ETA: 0s - loss: 27.4485WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2771 - val_loss: 16.3108 - lr: 0.0010\n","Epoch 24/40\n","196/200 [============================>.] - ETA: 0s - loss: 26.7950WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6079 - val_loss: 16.2772 - lr: 0.0010\n","Epoch 25/40\n","193/200 [===========================>..] - ETA: 0s - loss: 26.6138WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9826 - val_loss: 16.2869 - lr: 0.0010\n","Epoch 26/40\n","174/200 [=========================>....] - ETA: 0s - loss: 28.0924WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1807 - val_loss: 16.6467 - lr: 0.0010\n","Epoch 27/40\n","190/200 [===========================>..] - ETA: 0s - loss: 26.4785WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1305 - val_loss: 17.3942 - lr: 0.0010\n","Epoch 28/40\n","174/200 [=========================>....] - ETA: 0s - loss: 27.7681WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0209 - val_loss: 17.3521 - lr: 0.0010\n","Epoch 29/40\n","172/200 [========================>.....] - ETA: 0s - loss: 27.3272WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7797 - val_loss: 16.6352 - lr: 0.0010\n","Epoch 30/40\n","182/200 [==========================>...] - ETA: 0s - loss: 28.6320WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9860 - val_loss: 16.5527 - lr: 0.0010\n","Epoch 31/40\n","176/200 [=========================>....] - ETA: 0s - loss: 24.9242WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.7425 - val_loss: 16.5342 - lr: 0.0010\n","Epoch 32/40\n","181/200 [==========================>...] - ETA: 0s - loss: 27.1350WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4920 - val_loss: 16.3778 - lr: 0.0010\n","Epoch 33/40\n","181/200 [==========================>...] - ETA: 0s - loss: 26.4306WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4565 - val_loss: 16.3841 - lr: 0.0010\n","Epoch 34/40\n","147/200 [=====================>........] - ETA: 0s - loss: 26.7230WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7611 - val_loss: 17.3103 - lr: 0.0010\n","5/5 [==============================] - 0s 3ms/step - loss: 19.3248\n","CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 7.39 µs\n","Epoch 1/40\n","192/200 [===========================>..] - ETA: 0s - loss: 52.1011WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 3ms/step - loss: 51.2130 - val_loss: 18.7912 - lr: 0.0010\n","Epoch 2/40\n","196/200 [============================>.] - ETA: 0s - loss: 27.6200WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9139 - val_loss: 17.2468 - lr: 0.0010\n","Epoch 3/40\n","178/200 [=========================>....] - ETA: 0s - loss: 28.2842WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2394 - val_loss: 17.1679 - lr: 0.0010\n","Epoch 4/40\n","197/200 [============================>.] - ETA: 0s - loss: 29.0898WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.4440 - val_loss: 17.1573 - lr: 0.0010\n","Epoch 5/40\n","194/200 [============================>.] - ETA: 0s - loss: 27.1386WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2233 - val_loss: 17.1723 - lr: 0.0010\n","Epoch 6/40\n","199/200 [============================>.] - ETA: 0s - loss: 27.4573WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4263 - val_loss: 17.6556 - lr: 0.0010\n","Epoch 7/40\n","199/200 [============================>.] - ETA: 0s - loss: 28.0387WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9707 - val_loss: 17.1368 - lr: 0.0010\n","Epoch 8/40\n","189/200 [===========================>..] - ETA: 0s - loss: 27.3013WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2978 - val_loss: 16.9033 - lr: 0.0010\n","Epoch 9/40\n","196/200 [============================>.] - ETA: 0s - loss: 28.6513WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.7318 - val_loss: 16.8517 - lr: 0.0010\n","Epoch 10/40\n","183/200 [==========================>...] - ETA: 0s - loss: 25.5110WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.9002 - val_loss: 16.9526 - lr: 0.0010\n","Epoch 11/40\n","187/200 [===========================>..] - ETA: 0s - loss: 28.7538WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.3845 - val_loss: 16.7578 - lr: 0.0010\n","Epoch 12/40\n","196/200 [============================>.] - ETA: 0s - loss: 27.6295WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4641 - val_loss: 17.0192 - lr: 0.0010\n","Epoch 13/40\n","193/200 [===========================>..] - ETA: 0s - loss: 29.5163WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.9697 - val_loss: 17.0790 - lr: 0.0010\n","Epoch 14/40\n","194/200 [============================>.] - ETA: 0s - loss: 28.4132WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.1041 - val_loss: 16.6839 - lr: 0.0010\n","Epoch 15/40\n","189/200 [===========================>..] - ETA: 0s - loss: 27.2395WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2690 - val_loss: 16.7642 - lr: 0.0010\n","Epoch 16/40\n","197/200 [============================>.] - ETA: 0s - loss: 26.6382WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.5214 - val_loss: 16.5910 - lr: 0.0010\n","Epoch 17/40\n","191/200 [===========================>..] - ETA: 0s - loss: 27.6810WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9520 - val_loss: 17.0010 - lr: 0.0010\n","Epoch 18/40\n","179/200 [=========================>....] - ETA: 0s - loss: 27.0694WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.6640 - val_loss: 16.5631 - lr: 0.0010\n","Epoch 19/40\n","188/200 [===========================>..] - ETA: 0s - loss: 26.4396WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9449 - val_loss: 18.5243 - lr: 0.0010\n","Epoch 20/40\n","172/200 [========================>.....] - ETA: 0s - loss: 28.3681WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2201 - val_loss: 17.0078 - lr: 0.0010\n","Epoch 21/40\n","189/200 [===========================>..] - ETA: 0s - loss: 26.3299WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.9394 - val_loss: 16.8465 - lr: 0.0010\n","Epoch 22/40\n","198/200 [============================>.] - ETA: 0s - loss: 26.4102WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7430 - val_loss: 16.1857 - lr: 0.0010\n","Epoch 23/40\n","196/200 [============================>.] - ETA: 0s - loss: 27.0182WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4586 - val_loss: 17.2825 - lr: 0.0010\n","Epoch 24/40\n","193/200 [===========================>..] - ETA: 0s - loss: 25.9228WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7350 - val_loss: 16.4513 - lr: 0.0010\n","Epoch 25/40\n","182/200 [==========================>...] - ETA: 0s - loss: 27.1773WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9883 - val_loss: 16.2433 - lr: 0.0010\n","Epoch 26/40\n","188/200 [===========================>..] - ETA: 0s - loss: 25.6373WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.8531 - val_loss: 16.2562 - lr: 0.0010\n","Epoch 27/40\n","177/200 [=========================>....] - ETA: 0s - loss: 26.7887WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3697 - val_loss: 16.3265 - lr: 0.0010\n","Epoch 28/40\n","186/200 [==========================>...] - ETA: 0s - loss: 26.9543WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1380 - val_loss: 16.2314 - lr: 0.0010\n","Epoch 29/40\n","186/200 [==========================>...] - ETA: 0s - loss: 26.1000WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3777 - val_loss: 16.1705 - lr: 0.0010\n","Epoch 30/40\n","192/200 [===========================>..] - ETA: 0s - loss: 27.0115WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0407 - val_loss: 16.3515 - lr: 0.0010\n","Epoch 31/40\n","188/200 [===========================>..] - ETA: 0s - loss: 26.9937WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.5560 - val_loss: 16.2116 - lr: 0.0010\n","Epoch 32/40\n","194/200 [============================>.] - ETA: 0s - loss: 26.6779WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7869 - val_loss: 16.2649 - lr: 0.0010\n","Epoch 33/40\n","195/200 [============================>.] - ETA: 0s - loss: 25.9851WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4282 - val_loss: 17.9503 - lr: 0.0010\n","Epoch 34/40\n","138/200 [===================>..........] - ETA: 0s - loss: 26.0214WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.7551 - val_loss: 16.3936 - lr: 0.0010\n","5/5 [==============================] - 0s 3ms/step - loss: 18.6836\n","18.522626876831055\n","best n: 64\n","best l: 2\n","Model: \"sequential_106\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_387 (Dense)           (None, 64)                1472      \n","                                                                 \n"," dropout_131 (Dropout)       (None, 64)                0         \n","                                                                 \n"," dense_388 (Dense)           (None, 32)                2080      \n","                                                                 \n"," dropout_132 (Dropout)       (None, 32)                0         \n","                                                                 \n"," dense_389 (Dense)           (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 3,585\n","Trainable params: 3,585\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"WAtEVWpwnmMl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637964650581,"user_tz":300,"elapsed":41237,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"6471bf97-ddef-445c-8669-cf336c2824da"},"source":["sj_dnn_score, sj_dnn_model, sj_dnn_params = build_DNN_model(sj_train_2)\n","print(sj_dnn_score)\n","print(\"best n: \" + str(sj_dnn_params[0]))\n","print(\"best l: \" + str(sj_dnn_params[1]))\n","sj_dnn_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 8.11 µs\n","Epoch 1/40\n","168/200 [========================>.....] - ETA: 0s - loss: 91.8944 WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 2ms/step - loss: 83.8751 - val_loss: 17.9471 - lr: 0.0010\n","Epoch 2/40\n","191/200 [===========================>..] - ETA: 0s - loss: 38.8292WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 38.0713 - val_loss: 17.4134 - lr: 0.0010\n","Epoch 3/40\n","192/200 [===========================>..] - ETA: 0s - loss: 30.4798WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 30.5023 - val_loss: 16.8422 - lr: 0.0010\n","Epoch 4/40\n","170/200 [========================>.....] - ETA: 0s - loss: 29.2304WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.4975 - val_loss: 17.2403 - lr: 0.0010\n","Epoch 5/40\n","196/200 [============================>.] - ETA: 0s - loss: 28.3646WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.5710 - val_loss: 18.0413 - lr: 0.0010\n","Epoch 6/40\n","194/200 [============================>.] - ETA: 0s - loss: 26.7716WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2737 - val_loss: 16.8370 - lr: 0.0010\n","Epoch 7/40\n","171/200 [========================>.....] - ETA: 0s - loss: 27.4843WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.3515 - val_loss: 17.0695 - lr: 0.0010\n","Epoch 8/40\n","195/200 [============================>.] - ETA: 0s - loss: 28.8762WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.8686 - val_loss: 17.2578 - lr: 0.0010\n","Epoch 9/40\n","197/200 [============================>.] - ETA: 0s - loss: 28.5097WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2859 - val_loss: 17.0845 - lr: 0.0010\n","Epoch 10/40\n","198/200 [============================>.] - ETA: 0s - loss: 27.1057WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9645 - val_loss: 16.8270 - lr: 0.0010\n","Epoch 11/40\n","188/200 [===========================>..] - ETA: 0s - loss: 27.0148WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0342 - val_loss: 16.8315 - lr: 0.0010\n","Epoch 12/40\n","176/200 [=========================>....] - ETA: 0s - loss: 27.5025WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2267 - val_loss: 16.8193 - lr: 0.0010\n","Epoch 13/40\n","169/200 [========================>.....] - ETA: 0s - loss: 27.2097WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6923 - val_loss: 16.8509 - lr: 0.0010\n","Epoch 14/40\n","189/200 [===========================>..] - ETA: 0s - loss: 30.1883WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.3648 - val_loss: 16.8593 - lr: 0.0010\n","Epoch 15/40\n","169/200 [========================>.....] - ETA: 0s - loss: 27.9555WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1627 - val_loss: 16.8820 - lr: 0.0010\n","Epoch 16/40\n","192/200 [===========================>..] - ETA: 0s - loss: 27.9671WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8089 - val_loss: 16.7787 - lr: 0.0010\n","Epoch 17/40\n","194/200 [============================>.] - ETA: 0s - loss: 28.2593WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8180 - val_loss: 16.7485 - lr: 0.0010\n","Epoch 18/40\n","171/200 [========================>.....] - ETA: 0s - loss: 25.6173WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.7766 - val_loss: 16.9437 - lr: 0.0010\n","Epoch 19/40\n","172/200 [========================>.....] - ETA: 0s - loss: 28.2473WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2258 - val_loss: 16.6332 - lr: 0.0010\n","Epoch 20/40\n","173/200 [========================>.....] - ETA: 0s - loss: 27.9481WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1398 - val_loss: 16.6104 - lr: 0.0010\n","Epoch 21/40\n","171/200 [========================>.....] - ETA: 0s - loss: 27.1572WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1825 - val_loss: 16.8229 - lr: 0.0010\n","Epoch 22/40\n","174/200 [=========================>....] - ETA: 0s - loss: 27.0227WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9801 - val_loss: 16.7807 - lr: 0.0010\n","Epoch 23/40\n","184/200 [==========================>...] - ETA: 0s - loss: 27.1833WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.2827 - val_loss: 16.6017 - lr: 0.0010\n","Epoch 24/40\n","194/200 [============================>.] - ETA: 0s - loss: 26.4833WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8111 - val_loss: 16.5574 - lr: 0.0010\n","Epoch 25/40\n","169/200 [========================>.....] - ETA: 0s - loss: 26.9901WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9304 - val_loss: 16.4655 - lr: 0.0010\n","Epoch 26/40\n","182/200 [==========================>...] - ETA: 0s - loss: 27.1811WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1328 - val_loss: 16.4982 - lr: 0.0010\n","Epoch 27/40\n","167/200 [========================>.....] - ETA: 0s - loss: 27.0707WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8479 - val_loss: 16.4119 - lr: 0.0010\n","Epoch 28/40\n","184/200 [==========================>...] - ETA: 0s - loss: 26.3474WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0574 - val_loss: 16.2753 - lr: 0.0010\n","Epoch 29/40\n","173/200 [========================>.....] - ETA: 0s - loss: 25.0663WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.8733 - val_loss: 16.7543 - lr: 0.0010\n","Epoch 30/40\n","172/200 [========================>.....] - ETA: 0s - loss: 27.6337WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4156 - val_loss: 17.2205 - lr: 0.0010\n","Epoch 31/40\n","193/200 [===========================>..] - ETA: 0s - loss: 26.6425WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6336 - val_loss: 16.4449 - lr: 0.0010\n","Epoch 32/40\n","174/200 [=========================>....] - ETA: 0s - loss: 27.3517WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.9912 - val_loss: 16.9486 - lr: 0.0010\n","Epoch 33/40\n","197/200 [============================>.] - ETA: 0s - loss: 25.8925WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.8400 - val_loss: 16.1108 - lr: 0.0010\n","Epoch 34/40\n"," 66/200 [========>.....................] - ETA: 0s - loss: 30.9981WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 1ms/step - loss: 29.1986 - val_loss: 16.6067 - lr: 0.0010\n","5/5 [==============================] - 0s 4ms/step - loss: 21.4424\n","CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n","Wall time: 7.63 µs\n","Epoch 1/40\n","196/200 [============================>.] - ETA: 0s - loss: 64.4832WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 3ms/step - loss: 63.7147 - val_loss: 16.9575 - lr: 0.0010\n","Epoch 2/40\n","177/200 [=========================>....] - ETA: 0s - loss: 30.6539WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 30.2065 - val_loss: 17.0351 - lr: 0.0010\n","Epoch 3/40\n","184/200 [==========================>...] - ETA: 0s - loss: 29.4443WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.9590 - val_loss: 17.1194 - lr: 0.0010\n","Epoch 4/40\n","181/200 [==========================>...] - ETA: 0s - loss: 27.5995WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4494 - val_loss: 18.0627 - lr: 0.0010\n","Epoch 5/40\n","190/200 [===========================>..] - ETA: 0s - loss: 26.6671WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4852 - val_loss: 16.9767 - lr: 0.0010\n","Epoch 6/40\n","167/200 [========================>.....] - ETA: 0s - loss: 27.8069WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0263 - val_loss: 17.9216 - lr: 0.0010\n","Epoch 7/40\n","187/200 [===========================>..] - ETA: 0s - loss: 28.9164WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.3568 - val_loss: 17.5289 - lr: 0.0010\n","Epoch 8/40\n","190/200 [===========================>..] - ETA: 0s - loss: 28.4604WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.9521 - val_loss: 16.9782 - lr: 0.0010\n","Epoch 9/40\n","179/200 [=========================>....] - ETA: 0s - loss: 26.0114WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.7873 - val_loss: 17.4221 - lr: 0.0010\n","Epoch 10/40\n","176/200 [=========================>....] - ETA: 0s - loss: 27.5503WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.5665 - val_loss: 17.3674 - lr: 0.0010\n","Epoch 11/40\n","182/200 [==========================>...] - ETA: 0s - loss: 27.2717WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1363 - val_loss: 16.7066 - lr: 0.0010\n","Epoch 12/40\n","187/200 [===========================>..] - ETA: 0s - loss: 26.3588WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1731 - val_loss: 17.1824 - lr: 0.0010\n","Epoch 13/40\n","196/200 [============================>.] - ETA: 0s - loss: 29.1516WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.0265 - val_loss: 16.8287 - lr: 0.0010\n","Epoch 14/40\n","186/200 [==========================>...] - ETA: 0s - loss: 26.7982WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1225 - val_loss: 16.5336 - lr: 0.0010\n","Epoch 15/40\n","174/200 [=========================>....] - ETA: 0s - loss: 26.5688WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.2862 - val_loss: 16.5459 - lr: 0.0010\n","Epoch 16/40\n","193/200 [===========================>..] - ETA: 0s - loss: 26.7792WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9664 - val_loss: 16.7725 - lr: 0.0010\n","Epoch 17/40\n","188/200 [===========================>..] - ETA: 0s - loss: 25.1856WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.4851 - val_loss: 16.3648 - lr: 0.0010\n","Epoch 18/40\n","191/200 [===========================>..] - ETA: 0s - loss: 27.4936WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8104 - val_loss: 16.2473 - lr: 0.0010\n","Epoch 19/40\n","181/200 [==========================>...] - ETA: 0s - loss: 27.5062WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.7675 - val_loss: 19.5955 - lr: 0.0010\n","Epoch 20/40\n","176/200 [=========================>....] - ETA: 0s - loss: 26.8031WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1358 - val_loss: 16.6108 - lr: 0.0010\n","Epoch 21/40\n","187/200 [===========================>..] - ETA: 0s - loss: 26.3889WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8742 - val_loss: 17.0830 - lr: 0.0010\n","Epoch 22/40\n","192/200 [===========================>..] - ETA: 0s - loss: 26.6052WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4903 - val_loss: 16.3161 - lr: 0.0010\n","Epoch 23/40\n","182/200 [==========================>...] - ETA: 0s - loss: 25.3335WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.9804 - val_loss: 16.6291 - lr: 0.0010\n","Epoch 24/40\n","193/200 [===========================>..] - ETA: 0s - loss: 28.4555WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2345 - val_loss: 16.1208 - lr: 0.0010\n","Epoch 25/40\n","192/200 [===========================>..] - ETA: 0s - loss: 26.3634WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6159 - val_loss: 16.2114 - lr: 0.0010\n","Epoch 26/40\n","182/200 [==========================>...] - ETA: 0s - loss: 26.4432WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4569 - val_loss: 15.9981 - lr: 0.0010\n","Epoch 27/40\n","191/200 [===========================>..] - ETA: 0s - loss: 26.9619WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.6328 - val_loss: 16.3079 - lr: 0.0010\n","Epoch 28/40\n","189/200 [===========================>..] - ETA: 0s - loss: 26.0531WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.7669 - val_loss: 16.2221 - lr: 0.0010\n","Epoch 29/40\n","172/200 [========================>.....] - ETA: 0s - loss: 25.4806WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.5156 - val_loss: 15.8561 - lr: 0.0010\n","Epoch 30/40\n","183/200 [==========================>...] - ETA: 0s - loss: 26.5460WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0780 - val_loss: 15.8020 - lr: 0.0010\n","Epoch 31/40\n","181/200 [==========================>...] - ETA: 0s - loss: 25.8382WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.3432 - val_loss: 16.2076 - lr: 0.0010\n","Epoch 32/40\n","182/200 [==========================>...] - ETA: 0s - loss: 28.3055WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.7254 - val_loss: 15.9593 - lr: 0.0010\n","Epoch 33/40\n","184/200 [==========================>...] - ETA: 0s - loss: 24.0519WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 23.5244 - val_loss: 15.8677 - lr: 0.0010\n","Epoch 34/40\n"," 61/200 [========>.....................] - ETA: 0s - loss: 26.0096WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 1ms/step - loss: 27.1816 - val_loss: 17.1652 - lr: 0.0010\n","5/5 [==============================] - 0s 3ms/step - loss: 21.4587\n","CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n","Wall time: 7.39 µs\n","Epoch 1/40\n","172/200 [========================>.....] - ETA: 0s - loss: 60.8420WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 1s 3ms/step - loss: 56.7809 - val_loss: 16.9452 - lr: 0.0010\n","Epoch 2/40\n","188/200 [===========================>..] - ETA: 0s - loss: 28.3865WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.4610 - val_loss: 17.7304 - lr: 0.0010\n","Epoch 3/40\n","183/200 [==========================>...] - ETA: 0s - loss: 28.2583WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.5812 - val_loss: 17.8200 - lr: 0.0010\n","Epoch 4/40\n","187/200 [===========================>..] - ETA: 0s - loss: 28.3953WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 28.2289 - val_loss: 16.8689 - lr: 0.0010\n","Epoch 5/40\n","199/200 [============================>.] - ETA: 0s - loss: 27.4487WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.5100 - val_loss: 16.9004 - lr: 0.0010\n","Epoch 6/40\n","194/200 [============================>.] - ETA: 0s - loss: 27.9678WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.7354 - val_loss: 16.8555 - lr: 0.0010\n","Epoch 7/40\n","200/200 [==============================] - ETA: 0s - loss: 26.3663WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.3663 - val_loss: 17.2050 - lr: 0.0010\n","Epoch 8/40\n","191/200 [===========================>..] - ETA: 0s - loss: 29.4827WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 29.7160 - val_loss: 16.6639 - lr: 0.0010\n","Epoch 9/40\n","188/200 [===========================>..] - ETA: 0s - loss: 25.7144WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.5203 - val_loss: 16.9356 - lr: 0.0010\n","Epoch 10/40\n","192/200 [===========================>..] - ETA: 0s - loss: 26.7363WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4945 - val_loss: 20.9163 - lr: 0.0010\n","Epoch 11/40\n","199/200 [============================>.] - ETA: 0s - loss: 27.8788WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.8389 - val_loss: 17.6628 - lr: 0.0010\n","Epoch 12/40\n","191/200 [===========================>..] - ETA: 0s - loss: 27.0995WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.4413 - val_loss: 16.6220 - lr: 0.0010\n","Epoch 13/40\n","176/200 [=========================>....] - ETA: 0s - loss: 25.4273WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.9488 - val_loss: 16.6230 - lr: 0.0010\n","Epoch 14/40\n","189/200 [===========================>..] - ETA: 0s - loss: 28.0314WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.3998 - val_loss: 17.0416 - lr: 0.0010\n","Epoch 15/40\n","186/200 [==========================>...] - ETA: 0s - loss: 27.1692WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1353 - val_loss: 16.4873 - lr: 0.0010\n","Epoch 16/40\n","191/200 [===========================>..] - ETA: 0s - loss: 26.6161WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1234 - val_loss: 17.0781 - lr: 0.0010\n","Epoch 17/40\n","191/200 [===========================>..] - ETA: 0s - loss: 27.6329WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.2608 - val_loss: 17.3233 - lr: 0.0010\n","Epoch 18/40\n","186/200 [==========================>...] - ETA: 0s - loss: 25.2783WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.4464 - val_loss: 17.0564 - lr: 0.0010\n","Epoch 19/40\n","192/200 [===========================>..] - ETA: 0s - loss: 26.2683WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.1412 - val_loss: 16.3295 - lr: 0.0010\n","Epoch 20/40\n","190/200 [===========================>..] - ETA: 0s - loss: 27.2974WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1714 - val_loss: 16.5094 - lr: 0.0010\n","Epoch 21/40\n","197/200 [============================>.] - ETA: 0s - loss: 26.7774WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.7292 - val_loss: 16.5152 - lr: 0.0010\n","Epoch 22/40\n","193/200 [===========================>..] - ETA: 0s - loss: 27.8213WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.5288 - val_loss: 16.5849 - lr: 0.0010\n","Epoch 23/40\n","187/200 [===========================>..] - ETA: 0s - loss: 24.9040WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.7181 - val_loss: 16.2551 - lr: 0.0010\n","Epoch 24/40\n","193/200 [===========================>..] - ETA: 0s - loss: 27.0297WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8810 - val_loss: 16.3006 - lr: 0.0010\n","Epoch 25/40\n","199/200 [============================>.] - ETA: 0s - loss: 27.1621WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.0956 - val_loss: 16.1255 - lr: 0.0010\n","Epoch 26/40\n","190/200 [===========================>..] - ETA: 0s - loss: 25.7690WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 25.3274 - val_loss: 16.1659 - lr: 0.0010\n","Epoch 27/40\n","194/200 [============================>.] - ETA: 0s - loss: 27.9096WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.7111 - val_loss: 16.6097 - lr: 0.0010\n","Epoch 28/40\n","187/200 [===========================>..] - ETA: 0s - loss: 27.3604WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.9804 - val_loss: 15.9511 - lr: 0.0010\n","Epoch 29/40\n","185/200 [==========================>...] - ETA: 0s - loss: 24.0376WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.6711 - val_loss: 16.4118 - lr: 0.0010\n","Epoch 30/40\n","197/200 [============================>.] - ETA: 0s - loss: 27.4589WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 27.1511 - val_loss: 15.9744 - lr: 0.0010\n","Epoch 31/40\n","195/200 [============================>.] - ETA: 0s - loss: 26.3580WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.4911 - val_loss: 15.9268 - lr: 0.0010\n","Epoch 32/40\n","197/200 [============================>.] - ETA: 0s - loss: 24.4262WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 24.6124 - val_loss: 15.9056 - lr: 0.0010\n","Epoch 33/40\n","190/200 [===========================>..] - ETA: 0s - loss: 26.9378WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 2ms/step - loss: 26.8366 - val_loss: 16.7526 - lr: 0.0010\n","Epoch 34/40\n"," 77/200 [==========>...................] - ETA: 0s - loss: 23.6058WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8000 batches). You may need to use the repeat() function when building your dataset.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `mae` which is not available. Available metrics are: loss,val_loss,lr\n","200/200 [==============================] - 0s 1ms/step - loss: 25.7950 - val_loss: 16.0467 - lr: 0.0010\n","5/5 [==============================] - 0s 3ms/step - loss: 20.8797\n","20.879650115966797\n","best n: 256\n","best l: 2\n","Model: \"sequential_105\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_384 (Dense)           (None, 256)               5888      \n","                                                                 \n"," dropout_129 (Dropout)       (None, 256)               0         \n","                                                                 \n"," dense_385 (Dense)           (None, 128)               32896     \n","                                                                 \n"," dropout_130 (Dropout)       (None, 128)               0         \n","                                                                 \n"," dense_386 (Dense)           (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 38,913\n","Trainable params: 38,913\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"2DWwZ0SIj4cp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhekSHdcsrBW"},"source":["## Fit for IQ"]},{"cell_type":"code","metadata":{"id":"2i4H3GMhEyxq"},"source":["iq_dnn_score, iq_dnn_model,iq_dnn_params = build_DNN_model(iq_train)\n","print(iq_dnn_score)\n","print(\"best n: \" + str(iq_dnn_params[0]))\n","print(\"best l: \" + str(iq_dnn_params[1]))\n","iq_dnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltoSXwlQtdMJ"},"source":["iq_dnn_score, iq_dnn_model,iq_dnn_params = build_DNN_model(iq_train_2)\n","print(iq_dnn_score)\n","print(\"best n: \" + str(iq_dnn_params[0]))\n","print(\"best l: \" + str(iq_dnn_params[1]))\n","iq_dnn_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SYNaT_m_stBj"},"source":["## Submit Model 2"]},{"cell_type":"code","metadata":{"id":"UBwGzCfc6mwg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636929039143,"user_tz":300,"elapsed":20338,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"2dc464ac-455b-424d-cd5e-600284faf799"},"source":["now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission2_dnn_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_dnn_model.predict(sj_test).astype(int),iq_dnn_model.predict(iq_test).astype(int),name)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter change title: noNorm-Imputed\n"]}]},{"cell_type":"markdown","metadata":{"id":"ejK3Ahmhnh91"},"source":["# Model 3 -- Random Forest"]},{"cell_type":"markdown","metadata":{"id":"S7bxG8Wlxt5P"},"source":["## Build Model"]},{"cell_type":"code","metadata":{"id":"Rxok9ABQv111","executionInfo":{"status":"ok","timestamp":1638472492758,"user_tz":300,"elapsed":559,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}}},"source":["from sklearn.ensemble import RandomForestRegressor"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xKITcgknnbD","executionInfo":{"status":"ok","timestamp":1638472497311,"user_tz":300,"elapsed":292,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}}},"source":["def build_RF_ensemble(df,treeCounts):\n","  X = df.copy()\n","  y = X.pop('total_cases')\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.70,random_state = 42)\n","  \n","  bestModel = None\n","  bestScore = 1000000\n","  bestCount = 0\n","\n","  for n in treeCounts:\n","    # Instantiate model with n decision trees\n","    rf = RandomForestRegressor(n_estimators = n, random_state = 42)\n","\n","    # Train the model on training data\n","    rf.fit(X_train, y_train);\n","    predictions = rf.predict(X_test)\n","    rf_MAE = eval_measures.meanabs(predictions, y_test)\n","    print(n, rf_MAE)\n","\n","    if(rf_MAE < bestScore):\n","      bestScore = rf_MAE\n","      bestModel = rf\n","      bestCount = n\n","\n","\n","\n","  return bestScore, bestModel, bestCount"],"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8M53u5-xwFG"},"source":["## Fit for SJ"]},{"cell_type":"code","metadata":{"id":"DKicC2ayDc1t","executionInfo":{"status":"ok","timestamp":1638472499162,"user_tz":300,"elapsed":2,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}}},"source":["treeCounts = [50,100,250,500,1000]"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7cD529FnnYh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638331747594,"user_tz":300,"elapsed":15636,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"ef9051d5-ab17-4737-c016-a527b613db93"},"source":["sj_rf_score, sj_rf_model, sj_rf_treeCount = build_RF_ensemble(sj_train,treeCounts)\n","print(sj_rf_score)\n","print(\"tree count: \"+ str(sj_rf_treeCount))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50 17.913167259786476\n","100 17.655231316725978\n","250 17.223444839857653\n","500 17.176690391459076\n","1000 17.310839857651246\n","17.176690391459076\n","tree count: 500\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25vuBogwDIT2","executionInfo":{"status":"ok","timestamp":1638331763456,"user_tz":300,"elapsed":15872,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"93e98e61-2398-454a-fc42-5df74aa20baa"},"source":["sj_rf_score, sj_rf_model, sj_rf_treeCount = build_RF_ensemble(sj_train_2,treeCounts)\n","print(sj_rf_score)\n","print(\"tree count: \"+ str(sj_rf_treeCount))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50 18.489247311827956\n","100 17.663727598566307\n","250 17.265906810035844\n","500 17.233232974910393\n","1000 17.197806451612905\n","17.197806451612905\n","tree count: 1000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRu8qD6het6x","executionInfo":{"status":"ok","timestamp":1638331764046,"user_tz":300,"elapsed":602,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"0b1ac419-160b-4138-e7ef-5cf38c41d278"},"source":["x = sj_train.columns\n","x=x.drop('total_cases')\n","x = x.values\n","plt.barh(x, sj_rf_model.feature_importances_)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BarContainer object of 22 artists>"]},"metadata":{},"execution_count":23},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cR_y2aatfO5Z","executionInfo":{"status":"ok","timestamp":1638331764351,"user_tz":300,"elapsed":313,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"01f93e92-d5af-433d-9091-99d761e96e53"},"source":["sj_rf_model.feature_importances_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.29802116, 0.16102316, 0.02183101, 0.02323211, 0.08855248,\n","       0.03528769, 0.01548138, 0.02218517, 0.0112989 , 0.0293977 ,\n","       0.01749438, 0.01084786, 0.03100211, 0.03396758, 0.014357  ,\n","       0.03190629, 0.03952549, 0.01703885, 0.02185915, 0.04492127,\n","       0.00684855, 0.02392071])"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"C5vCqLolK9ey"},"source":["out = pd.DataFrame({'labels':x, 'values':sj_rf_model.feature_importances_})\n","out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttnboi_yLw2o"},"source":["path='/gdrive/MyDrive/Undergraduate_Thesis_Duncan/submissions'\n","name = \"bargraph.csv\"\n","path = os.path.join(path,name)\n","out.to_csv(path,index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gWvVoyFOkZFP","executionInfo":{"status":"ok","timestamp":1638472660564,"user_tz":300,"elapsed":4925,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"d6643c93-3f82-4d17-f400-7dc02c7f2d75"},"source":["sj_rf_score, sj_rf_model, sj_rf_treeCount = build_RF_ensemble(reduced_train_sj,treeCounts)\n","print(sj_rf_score)\n","print(\"tree count: \"+ str(sj_rf_treeCount))"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["50 10.19067615658363\n","100 10.135124555160141\n","250 10.187886120996438\n","500 10.370697508896798\n","1000 10.399758007117438\n","10.135124555160141\n","tree count: 100\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CuXkXz3EkZCI","executionInfo":{"status":"ok","timestamp":1638472676634,"user_tz":300,"elapsed":4920,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"8f9e21b4-fc71-4c07-b938-b96ea56151bc"},"source":["sj_rf_score, sj_rf_model, sj_rf_treeCount = build_RF_ensemble(reduced_train_sj_2,treeCounts)\n","print(sj_rf_score)\n","print(\"tree count: \"+ str(sj_rf_treeCount))"],"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["50 11.049605734767026\n","100 11.228960573476703\n","250 11.314408602150538\n","500 11.314078853046595\n","1000 11.283594982078851\n","11.049605734767026\n","tree count: 50\n"]}]},{"cell_type":"code","metadata":{"id":"klrad2aokY6j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Qu4VxUzxxzu"},"source":["## Fit for IQ"]},{"cell_type":"code","metadata":{"id":"CJaxRqt6nnV2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638319967477,"user_tz":300,"elapsed":9486,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"fb823142-369a-403e-e409-107c61208a45"},"source":["iq_rf_score, iq_rf_model,iq_rf_treeCount = build_RF_ensemble(iq_train,treeCounts)\n","print(iq_rf_score)\n","print(\"tree count: \"+ str(iq_rf_treeCount))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50 6.128589743589743\n","100 6.00275641025641\n","250 5.987589743589744\n","500 5.950217948717948\n","1000 5.9518589743589745\n","5.950217948717948\n","tree count: 500\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfhsqAz1DNr1","executionInfo":{"status":"ok","timestamp":1638319976845,"user_tz":300,"elapsed":9377,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"aa608f16-0712-49c9-b614-988b6febd086"},"source":["iq_rf_score, iq_rf_model,iq_rf_treeCount = build_RF_ensemble(iq_train_2,treeCounts)\n","print(iq_rf_score)\n","print(\"tree count: \"+ str(iq_rf_treeCount))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50 5.861806451612903\n","100 5.77232258064516\n","250 5.800309677419355\n","500 5.7712387096774185\n","1000 5.771645161290322\n","5.7712387096774185\n","tree count: 500\n"]}]},{"cell_type":"code","metadata":{"id":"Fn4BD0QjRx1D"},"source":["sj_rf_model.get_params()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eV_cauKfkpqy","executionInfo":{"status":"ok","timestamp":1638472652063,"user_tz":300,"elapsed":3955,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"a9cc3aed-a809-4248-97e5-57c56d1a60dc"},"source":["iq_rf_score, iq_rf_model,iq_rf_treeCount = build_RF_ensemble(reduced_train_iq,treeCounts)\n","print(iq_rf_score)\n","print(\"tree count: \"+ str(iq_rf_treeCount))"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["50 4.968076923076923\n","100 4.839358974358975\n","250 4.946512820512821\n","500 4.927423076923077\n","1000 4.94225\n","4.839358974358975\n","tree count: 100\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5jooSBZkqCG","executionInfo":{"status":"ok","timestamp":1638472680623,"user_tz":300,"elapsed":3991,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"0c9a6d07-4b12-494f-9d7d-3fe797f9b1b6"},"source":["iq_rf_score, iq_rf_model,iq_rf_treeCount = build_RF_ensemble(reduced_train_iq_2,treeCounts)\n","print(iq_rf_score)\n","print(\"tree count: \"+ str(iq_rf_treeCount))"],"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["50 5.110322580645161\n","100 4.955225806451613\n","250 4.892103225806452\n","500 4.7904\n","1000 4.788522580645162\n","4.788522580645162\n","tree count: 1000\n"]}]},{"cell_type":"markdown","metadata":{"id":"DJ3S3_qTxzgc"},"source":["## Submit Model 3"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"MzcB6C0RufOf","executionInfo":{"status":"ok","timestamp":1638475112124,"user_tz":300,"elapsed":364,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"de2ab48a-f721-4fc4-9cca-df4ef45af5b8"},"source":["total.corr()"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>year</th>\n","      <th>weekofyear</th>\n","      <th>ndvi_ne</th>\n","      <th>ndvi_nw</th>\n","      <th>ndvi_se</th>\n","      <th>ndvi_sw</th>\n","      <th>precipitation_amt_mm</th>\n","      <th>reanalysis_air_temp_k</th>\n","      <th>reanalysis_avg_temp_k</th>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <th>reanalysis_tdtr_k</th>\n","      <th>station_avg_temp_c</th>\n","      <th>station_diur_temp_rng_c</th>\n","      <th>station_max_temp_c</th>\n","      <th>station_min_temp_c</th>\n","      <th>station_precip_mm</th>\n","      <th>total_cases</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>year</th>\n","      <td>1.000000</td>\n","      <td>-0.071649</td>\n","      <td>0.223361</td>\n","      <td>0.144345</td>\n","      <td>0.234234</td>\n","      <td>0.277759</td>\n","      <td>0.205302</td>\n","      <td>-0.140016</td>\n","      <td>0.085043</td>\n","      <td>0.132273</td>\n","      <td>0.480402</td>\n","      <td>-0.392351</td>\n","      <td>0.132625</td>\n","      <td>0.336349</td>\n","      <td>0.205302</td>\n","      <td>0.161596</td>\n","      <td>0.490542</td>\n","      <td>0.047010</td>\n","      <td>0.373644</td>\n","      <td>0.227320</td>\n","      <td>-0.214482</td>\n","      <td>0.219910</td>\n","      <td>-0.306806</td>\n","    </tr>\n","    <tr>\n","      <th>weekofyear</th>\n","      <td>-0.071649</td>\n","      <td>1.000000</td>\n","      <td>0.053548</td>\n","      <td>0.048759</td>\n","      <td>0.121557</td>\n","      <td>0.068701</td>\n","      <td>0.118037</td>\n","      <td>0.425753</td>\n","      <td>0.463677</td>\n","      <td>0.348946</td>\n","      <td>0.238078</td>\n","      <td>0.179679</td>\n","      <td>0.072955</td>\n","      <td>-0.015191</td>\n","      <td>0.118037</td>\n","      <td>0.350821</td>\n","      <td>0.077933</td>\n","      <td>0.368408</td>\n","      <td>0.023220</td>\n","      <td>0.232098</td>\n","      <td>0.292362</td>\n","      <td>0.066294</td>\n","      <td>0.216452</td>\n","    </tr>\n","    <tr>\n","      <th>ndvi_ne</th>\n","      <td>0.223361</td>\n","      <td>0.053548</td>\n","      <td>1.000000</td>\n","      <td>0.850902</td>\n","      <td>0.614380</td>\n","      <td>0.669504</td>\n","      <td>0.205736</td>\n","      <td>-0.340976</td>\n","      <td>-0.037682</td>\n","      <td>0.056077</td>\n","      <td>0.634330</td>\n","      <td>-0.623116</td>\n","      <td>0.199411</td>\n","      <td>0.457985</td>\n","      <td>0.205736</td>\n","      <td>0.094852</td>\n","      <td>0.673935</td>\n","      <td>0.186227</td>\n","      <td>0.658129</td>\n","      <td>0.491922</td>\n","      <td>-0.315696</td>\n","      <td>0.242263</td>\n","      <td>-0.241376</td>\n","    </tr>\n","    <tr>\n","      <th>ndvi_nw</th>\n","      <td>0.144345</td>\n","      <td>0.048759</td>\n","      <td>0.850902</td>\n","      <td>1.000000</td>\n","      <td>0.555809</td>\n","      <td>0.651938</td>\n","      <td>0.193563</td>\n","      <td>-0.317862</td>\n","      <td>-0.030974</td>\n","      <td>0.063289</td>\n","      <td>0.606775</td>\n","      <td>-0.588806</td>\n","      <td>0.190989</td>\n","      <td>0.449152</td>\n","      <td>0.193563</td>\n","      <td>0.100626</td>\n","      <td>0.645596</td>\n","      <td>0.203975</td>\n","      <td>0.649483</td>\n","      <td>0.490122</td>\n","      <td>-0.304206</td>\n","      <td>0.221314</td>\n","      <td>-0.202235</td>\n","    </tr>\n","    <tr>\n","      <th>ndvi_se</th>\n","      <td>0.234234</td>\n","      <td>0.121557</td>\n","      <td>0.614380</td>\n","      <td>0.555809</td>\n","      <td>1.000000</td>\n","      <td>0.820924</td>\n","      <td>0.074633</td>\n","      <td>-0.157447</td>\n","      <td>0.051348</td>\n","      <td>0.002810</td>\n","      <td>0.468054</td>\n","      <td>-0.407931</td>\n","      <td>0.034792</td>\n","      <td>0.215606</td>\n","      <td>0.074633</td>\n","      <td>0.028795</td>\n","      <td>0.486047</td>\n","      <td>0.089242</td>\n","      <td>0.449599</td>\n","      <td>0.290691</td>\n","      <td>-0.251621</td>\n","      <td>0.131326</td>\n","      <td>-0.168612</td>\n","    </tr>\n","    <tr>\n","      <th>ndvi_sw</th>\n","      <td>0.277759</td>\n","      <td>0.068701</td>\n","      <td>0.669504</td>\n","      <td>0.651938</td>\n","      <td>0.820924</td>\n","      <td>1.000000</td>\n","      <td>0.124047</td>\n","      <td>-0.227824</td>\n","      <td>0.022533</td>\n","      <td>0.020746</td>\n","      <td>0.546460</td>\n","      <td>-0.494284</td>\n","      <td>0.101652</td>\n","      <td>0.311759</td>\n","      <td>0.124047</td>\n","      <td>0.053437</td>\n","      <td>0.569554</td>\n","      <td>0.121060</td>\n","      <td>0.545899</td>\n","      <td>0.377393</td>\n","      <td>-0.294684</td>\n","      <td>0.158345</td>\n","      <td>-0.196461</td>\n","    </tr>\n","    <tr>\n","      <th>precipitation_amt_mm</th>\n","      <td>0.205302</td>\n","      <td>0.118037</td>\n","      <td>0.205736</td>\n","      <td>0.193563</td>\n","      <td>0.074633</td>\n","      <td>0.124047</td>\n","      <td>1.000000</td>\n","      <td>-0.017229</td>\n","      <td>0.106384</td>\n","      <td>0.434722</td>\n","      <td>0.282721</td>\n","      <td>-0.119691</td>\n","      <td>0.481159</td>\n","      <td>0.499984</td>\n","      <td>1.000000</td>\n","      <td>0.451202</td>\n","      <td>0.201427</td>\n","      <td>0.225408</td>\n","      <td>0.193358</td>\n","      <td>0.296215</td>\n","      <td>0.076680</td>\n","      <td>0.486637</td>\n","      <td>-0.038740</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_air_temp_k</th>\n","      <td>-0.140016</td>\n","      <td>0.425753</td>\n","      <td>-0.340976</td>\n","      <td>-0.317862</td>\n","      <td>-0.157447</td>\n","      <td>-0.227824</td>\n","      <td>-0.017229</td>\n","      <td>1.000000</td>\n","      <td>0.901777</td>\n","      <td>0.529771</td>\n","      <td>-0.001211</td>\n","      <td>0.736765</td>\n","      <td>-0.128219</td>\n","      <td>-0.402338</td>\n","      <td>-0.017229</td>\n","      <td>0.508380</td>\n","      <td>-0.280375</td>\n","      <td>0.619974</td>\n","      <td>-0.261457</td>\n","      <td>0.227768</td>\n","      <td>0.719612</td>\n","      <td>-0.173851</td>\n","      <td>0.264952</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_avg_temp_k</th>\n","      <td>0.085043</td>\n","      <td>0.463677</td>\n","      <td>-0.037682</td>\n","      <td>-0.030974</td>\n","      <td>0.051348</td>\n","      <td>0.022533</td>\n","      <td>0.106384</td>\n","      <td>0.901777</td>\n","      <td>1.000000</td>\n","      <td>0.614268</td>\n","      <td>0.398224</td>\n","      <td>0.436689</td>\n","      <td>-0.031728</td>\n","      <td>-0.168371</td>\n","      <td>0.106384</td>\n","      <td>0.612484</td>\n","      <td>0.124200</td>\n","      <td>0.751330</td>\n","      <td>0.107581</td>\n","      <td>0.512220</td>\n","      <td>0.579864</td>\n","      <td>-0.048052</td>\n","      <td>0.151637</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_dew_point_temp_k</th>\n","      <td>0.132273</td>\n","      <td>0.348946</td>\n","      <td>0.056077</td>\n","      <td>0.063289</td>\n","      <td>0.002810</td>\n","      <td>0.020746</td>\n","      <td>0.434722</td>\n","      <td>0.529771</td>\n","      <td>0.614268</td>\n","      <td>1.000000</td>\n","      <td>0.257380</td>\n","      <td>0.361781</td>\n","      <td>0.432970</td>\n","      <td>0.553766</td>\n","      <td>0.434722</td>\n","      <td>0.997051</td>\n","      <td>-0.033512</td>\n","      <td>0.743506</td>\n","      <td>0.037151</td>\n","      <td>0.492319</td>\n","      <td>0.651535</td>\n","      <td>0.241335</td>\n","      <td>0.142531</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_max_air_temp_k</th>\n","      <td>0.480402</td>\n","      <td>0.238078</td>\n","      <td>0.634330</td>\n","      <td>0.606775</td>\n","      <td>0.468054</td>\n","      <td>0.546460</td>\n","      <td>0.282721</td>\n","      <td>-0.001211</td>\n","      <td>0.398224</td>\n","      <td>0.257380</td>\n","      <td>1.000000</td>\n","      <td>-0.600850</td>\n","      <td>0.192261</td>\n","      <td>0.400093</td>\n","      <td>0.282721</td>\n","      <td>0.300278</td>\n","      <td>0.918578</td>\n","      <td>0.469668</td>\n","      <td>0.834263</td>\n","      <td>0.763446</td>\n","      <td>-0.193709</td>\n","      <td>0.251177</td>\n","      <td>-0.191345</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_min_air_temp_k</th>\n","      <td>-0.392351</td>\n","      <td>0.179679</td>\n","      <td>-0.623116</td>\n","      <td>-0.588806</td>\n","      <td>-0.407931</td>\n","      <td>-0.494284</td>\n","      <td>-0.119691</td>\n","      <td>0.736765</td>\n","      <td>0.436689</td>\n","      <td>0.361781</td>\n","      <td>-0.600850</td>\n","      <td>1.000000</td>\n","      <td>-0.105815</td>\n","      <td>-0.410714</td>\n","      <td>-0.119691</td>\n","      <td>0.318592</td>\n","      <td>-0.815511</td>\n","      <td>0.216543</td>\n","      <td>-0.715676</td>\n","      <td>-0.271495</td>\n","      <td>0.720701</td>\n","      <td>-0.237142</td>\n","      <td>0.325252</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_precip_amt_kg_per_m2</th>\n","      <td>0.132625</td>\n","      <td>0.072955</td>\n","      <td>0.199411</td>\n","      <td>0.190989</td>\n","      <td>0.034792</td>\n","      <td>0.101652</td>\n","      <td>0.481159</td>\n","      <td>-0.128219</td>\n","      <td>-0.031728</td>\n","      <td>0.432970</td>\n","      <td>0.192261</td>\n","      <td>-0.105815</td>\n","      <td>1.000000</td>\n","      <td>0.593928</td>\n","      <td>0.481159</td>\n","      <td>0.452708</td>\n","      <td>0.094050</td>\n","      <td>0.148553</td>\n","      <td>0.138502</td>\n","      <td>0.196447</td>\n","      <td>0.056777</td>\n","      <td>0.348936</td>\n","      <td>-0.010031</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_relative_humidity_percent</th>\n","      <td>0.336349</td>\n","      <td>-0.015191</td>\n","      <td>0.457985</td>\n","      <td>0.449152</td>\n","      <td>0.215606</td>\n","      <td>0.311759</td>\n","      <td>0.499984</td>\n","      <td>-0.402338</td>\n","      <td>-0.168371</td>\n","      <td>0.553766</td>\n","      <td>0.400093</td>\n","      <td>-0.410714</td>\n","      <td>0.593928</td>\n","      <td>1.000000</td>\n","      <td>0.499984</td>\n","      <td>0.577813</td>\n","      <td>0.360026</td>\n","      <td>0.243385</td>\n","      <td>0.405907</td>\n","      <td>0.395935</td>\n","      <td>-0.042639</td>\n","      <td>0.450741</td>\n","      <td>-0.132452</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_sat_precip_amt_mm</th>\n","      <td>0.205302</td>\n","      <td>0.118037</td>\n","      <td>0.205736</td>\n","      <td>0.193563</td>\n","      <td>0.074633</td>\n","      <td>0.124047</td>\n","      <td>1.000000</td>\n","      <td>-0.017229</td>\n","      <td>0.106384</td>\n","      <td>0.434722</td>\n","      <td>0.282721</td>\n","      <td>-0.119691</td>\n","      <td>0.481159</td>\n","      <td>0.499984</td>\n","      <td>1.000000</td>\n","      <td>0.451202</td>\n","      <td>0.201427</td>\n","      <td>0.225408</td>\n","      <td>0.193358</td>\n","      <td>0.296215</td>\n","      <td>0.076680</td>\n","      <td>0.486637</td>\n","      <td>-0.038740</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_specific_humidity_g_per_kg</th>\n","      <td>0.161596</td>\n","      <td>0.350821</td>\n","      <td>0.094852</td>\n","      <td>0.100626</td>\n","      <td>0.028795</td>\n","      <td>0.053437</td>\n","      <td>0.451202</td>\n","      <td>0.508380</td>\n","      <td>0.612484</td>\n","      <td>0.997051</td>\n","      <td>0.300278</td>\n","      <td>0.318592</td>\n","      <td>0.452708</td>\n","      <td>0.577813</td>\n","      <td>0.451202</td>\n","      <td>1.000000</td>\n","      <td>0.012948</td>\n","      <td>0.747809</td>\n","      <td>0.080273</td>\n","      <td>0.519376</td>\n","      <td>0.623155</td>\n","      <td>0.255836</td>\n","      <td>0.129861</td>\n","    </tr>\n","    <tr>\n","      <th>reanalysis_tdtr_k</th>\n","      <td>0.490542</td>\n","      <td>0.077933</td>\n","      <td>0.673935</td>\n","      <td>0.645596</td>\n","      <td>0.486047</td>\n","      <td>0.569554</td>\n","      <td>0.201427</td>\n","      <td>-0.280375</td>\n","      <td>0.124200</td>\n","      <td>-0.033512</td>\n","      <td>0.918578</td>\n","      <td>-0.815511</td>\n","      <td>0.094050</td>\n","      <td>0.360026</td>\n","      <td>0.201427</td>\n","      <td>0.012948</td>\n","      <td>1.000000</td>\n","      <td>0.217067</td>\n","      <td>0.881176</td>\n","      <td>0.613477</td>\n","      <td>-0.451940</td>\n","      <td>0.232783</td>\n","      <td>-0.278483</td>\n","    </tr>\n","    <tr>\n","      <th>station_avg_temp_c</th>\n","      <td>0.047010</td>\n","      <td>0.368408</td>\n","      <td>0.186227</td>\n","      <td>0.203975</td>\n","      <td>0.089242</td>\n","      <td>0.121060</td>\n","      <td>0.225408</td>\n","      <td>0.619974</td>\n","      <td>0.751330</td>\n","      <td>0.743506</td>\n","      <td>0.469668</td>\n","      <td>0.216543</td>\n","      <td>0.148553</td>\n","      <td>0.243385</td>\n","      <td>0.225408</td>\n","      <td>0.747809</td>\n","      <td>0.217067</td>\n","      <td>1.000000</td>\n","      <td>0.303850</td>\n","      <td>0.764576</td>\n","      <td>0.633252</td>\n","      <td>0.063144</td>\n","      <td>0.116109</td>\n","    </tr>\n","    <tr>\n","      <th>station_diur_temp_rng_c</th>\n","      <td>0.373644</td>\n","      <td>0.023220</td>\n","      <td>0.658129</td>\n","      <td>0.649483</td>\n","      <td>0.449599</td>\n","      <td>0.545899</td>\n","      <td>0.193358</td>\n","      <td>-0.261457</td>\n","      <td>0.107581</td>\n","      <td>0.037151</td>\n","      <td>0.834263</td>\n","      <td>-0.715676</td>\n","      <td>0.138502</td>\n","      <td>0.405907</td>\n","      <td>0.193358</td>\n","      <td>0.080273</td>\n","      <td>0.881176</td>\n","      <td>0.303850</td>\n","      <td>1.000000</td>\n","      <td>0.715217</td>\n","      <td>-0.439345</td>\n","      <td>0.179648</td>\n","      <td>-0.237844</td>\n","    </tr>\n","    <tr>\n","      <th>station_max_temp_c</th>\n","      <td>0.227320</td>\n","      <td>0.232098</td>\n","      <td>0.491922</td>\n","      <td>0.490122</td>\n","      <td>0.290691</td>\n","      <td>0.377393</td>\n","      <td>0.296215</td>\n","      <td>0.227768</td>\n","      <td>0.512220</td>\n","      <td>0.492319</td>\n","      <td>0.763446</td>\n","      <td>-0.271495</td>\n","      <td>0.196447</td>\n","      <td>0.395935</td>\n","      <td>0.296215</td>\n","      <td>0.519376</td>\n","      <td>0.613477</td>\n","      <td>0.764576</td>\n","      <td>0.715217</td>\n","      <td>1.000000</td>\n","      <td>0.140521</td>\n","      <td>0.167098</td>\n","      <td>-0.039219</td>\n","    </tr>\n","    <tr>\n","      <th>station_min_temp_c</th>\n","      <td>-0.214482</td>\n","      <td>0.292362</td>\n","      <td>-0.315696</td>\n","      <td>-0.304206</td>\n","      <td>-0.251621</td>\n","      <td>-0.294684</td>\n","      <td>0.076680</td>\n","      <td>0.719612</td>\n","      <td>0.579864</td>\n","      <td>0.651535</td>\n","      <td>-0.193709</td>\n","      <td>0.720701</td>\n","      <td>0.056777</td>\n","      <td>-0.042639</td>\n","      <td>0.076680</td>\n","      <td>0.623155</td>\n","      <td>-0.451940</td>\n","      <td>0.633252</td>\n","      <td>-0.439345</td>\n","      <td>0.140521</td>\n","      <td>1.000000</td>\n","      <td>-0.050110</td>\n","      <td>0.267109</td>\n","    </tr>\n","    <tr>\n","      <th>station_precip_mm</th>\n","      <td>0.219910</td>\n","      <td>0.066294</td>\n","      <td>0.242263</td>\n","      <td>0.221314</td>\n","      <td>0.131326</td>\n","      <td>0.158345</td>\n","      <td>0.486637</td>\n","      <td>-0.173851</td>\n","      <td>-0.048052</td>\n","      <td>0.241335</td>\n","      <td>0.251177</td>\n","      <td>-0.237142</td>\n","      <td>0.348936</td>\n","      <td>0.450741</td>\n","      <td>0.486637</td>\n","      <td>0.255836</td>\n","      <td>0.232783</td>\n","      <td>0.063144</td>\n","      <td>0.179648</td>\n","      <td>0.167098</td>\n","      <td>-0.050110</td>\n","      <td>1.000000</td>\n","      <td>-0.074374</td>\n","    </tr>\n","    <tr>\n","      <th>total_cases</th>\n","      <td>-0.306806</td>\n","      <td>0.216452</td>\n","      <td>-0.241376</td>\n","      <td>-0.202235</td>\n","      <td>-0.168612</td>\n","      <td>-0.196461</td>\n","      <td>-0.038740</td>\n","      <td>0.264952</td>\n","      <td>0.151637</td>\n","      <td>0.142531</td>\n","      <td>-0.191345</td>\n","      <td>0.325252</td>\n","      <td>-0.010031</td>\n","      <td>-0.132452</td>\n","      <td>-0.038740</td>\n","      <td>0.129861</td>\n","      <td>-0.278483</td>\n","      <td>0.116109</td>\n","      <td>-0.237844</td>\n","      <td>-0.039219</td>\n","      <td>0.267109</td>\n","      <td>-0.074374</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           year  ...  total_cases\n","year                                   1.000000  ...    -0.306806\n","weekofyear                            -0.071649  ...     0.216452\n","ndvi_ne                                0.223361  ...    -0.241376\n","ndvi_nw                                0.144345  ...    -0.202235\n","ndvi_se                                0.234234  ...    -0.168612\n","ndvi_sw                                0.277759  ...    -0.196461\n","precipitation_amt_mm                   0.205302  ...    -0.038740\n","reanalysis_air_temp_k                 -0.140016  ...     0.264952\n","reanalysis_avg_temp_k                  0.085043  ...     0.151637\n","reanalysis_dew_point_temp_k            0.132273  ...     0.142531\n","reanalysis_max_air_temp_k              0.480402  ...    -0.191345\n","reanalysis_min_air_temp_k             -0.392351  ...     0.325252\n","reanalysis_precip_amt_kg_per_m2        0.132625  ...    -0.010031\n","reanalysis_relative_humidity_percent   0.336349  ...    -0.132452\n","reanalysis_sat_precip_amt_mm           0.205302  ...    -0.038740\n","reanalysis_specific_humidity_g_per_kg  0.161596  ...     0.129861\n","reanalysis_tdtr_k                      0.490542  ...    -0.278483\n","station_avg_temp_c                     0.047010  ...     0.116109\n","station_diur_temp_rng_c                0.373644  ...    -0.237844\n","station_max_temp_c                     0.227320  ...    -0.039219\n","station_min_temp_c                    -0.214482  ...     0.267109\n","station_precip_mm                      0.219910  ...    -0.074374\n","total_cases                           -0.306806  ...     1.000000\n","\n","[23 rows x 23 columns]"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"oPmpHVW8nnTJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634523502115,"user_tz":240,"elapsed":7060,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"89fafe13-ede5-4704-a436-4eea24d20e2f"},"source":["now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission3_rf_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_rf_model.predict(sj_test).astype(int),iq_rf_model.predict(iq_test).astype(int),name)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter change title: tree_count_loop2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tpj0KxllC-4","executionInfo":{"status":"ok","timestamp":1638472684725,"user_tz":300,"elapsed":4128,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"5578bde2-100d-4eb4-ffc1-17f4b993ff96"},"source":["#reduced model\n","now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission3_rf_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_rf_model.predict(reduced_test_sj).astype(int),iq_rf_model.predict(reduced_test_iq).astype(int),name)"],"execution_count":67,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter change title: rf red 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"cc7emXmithix"},"source":["# Model 4 -- XGBoost"]},{"cell_type":"markdown","metadata":{"id":"A3MojrlCsu5A"},"source":["## Build Model"]},{"cell_type":"code","metadata":{"id":"7u_Hng7YtknL"},"source":["from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import RepeatedKFold\n","from xgboost import XGBRegressor\n","\n","def build_XGBoost_model(df):\n"," \n","\n","  X = df.copy()\n","  y = X.pop('total_cases')\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.70,random_state = 42)\n","\n","  model = XGBRegressor(n_estimators=50, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n","  # define model evaluation method\n","  #cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=42)\n","  # evaluate model\n","  #scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n","  # force scores to be positive\n"," # scores = absolute(scores)\n"," # print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )\n","  model.fit(X_train,y_train)\n","\n","\n","  #Predict the response for test dataset\n","  predictions = model.predict(X_test)\n","  score = eval_measures.meanabs(predictions, y_test)\n","\n","  return score, model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kXEawFLmx6am"},"source":["## Fit for SJ"]},{"cell_type":"code","metadata":{"id":"MonJv94ItlAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638470112589,"user_tz":300,"elapsed":265,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"759cebe7-1563-45e2-c3f0-bf4cb6bb86b9"},"source":["sj_xgb_score, sj_xgb_model = build_XGBoost_model(sj_train)\n","print(sj_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:35:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","16.628853823366537\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PmUTQ_vA_CRC","executionInfo":{"status":"ok","timestamp":1638470114500,"user_tz":300,"elapsed":2,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"268f095e-a721-4ceb-be9c-eab47f79a884"},"source":["sj_xgb_score, sj_xgb_model = build_XGBoost_model(sj_train_2)\n","print(sj_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:35:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","15.216146022188193\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3hOaX7ofCw_","executionInfo":{"status":"ok","timestamp":1638471078814,"user_tz":300,"elapsed":303,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"f988eee7-f003-4d76-95dc-245a7f06cc58"},"source":["sj_xgb_score, sj_xgb_model = build_XGBoost_model(reduced_train_sj)\n","print(sj_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:51:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","15.4736755725752\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3M2KbLKf9cg","executionInfo":{"status":"ok","timestamp":1638471298451,"user_tz":300,"elapsed":278,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"efc6fe86-e200-4ba8-c0b5-a3b5476edfc2"},"source":["sj_xgb_score, sj_xgb_model = build_XGBoost_model(reduced_train_sj_2)\n","print(sj_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:54:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","13.366739177041584\n"]}]},{"cell_type":"markdown","metadata":{"id":"IsR0j7Xbx756"},"source":["## Fit for IQ"]},{"cell_type":"code","metadata":{"id":"MYXtiRfYtk-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638470118785,"user_tz":300,"elapsed":284,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"9f24e977-c86f-4fb8-8946-be5176a109dc"},"source":["iq_xgb_score, iq_xgb_model = build_XGBoost_model(iq_train)\n","print(iq_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:35:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","5.27874578592869\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVhjev7F_FSp","executionInfo":{"status":"ok","timestamp":1638470119846,"user_tz":300,"elapsed":3,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"c3bb3734-dfe0-4a7f-db37-8761e2f2b939"},"source":["iq_xgb_score, iq_xgb_model = build_XGBoost_model(iq_train_2)\n","print(iq_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:35:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","5.7482706300673945\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfQuSGhDeVsS","executionInfo":{"status":"ok","timestamp":1638471080045,"user_tz":300,"elapsed":2,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"8ba05dce-6913-414c-e50a-91dd6e78c18d"},"source":["iq_xgb_score, iq_xgb_model = build_XGBoost_model(reduced_train_iq)\n","print(iq_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:51:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","4.747528336560115\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gYmroBmgACM","executionInfo":{"status":"ok","timestamp":1638471314745,"user_tz":300,"elapsed":261,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"e6183738-e151-4ccc-8b52-00715eaea4ff"},"source":["iq_xgb_score, iq_xgb_model = build_XGBoost_model(reduced_train_iq_2)\n","print(iq_xgb_score)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18:55:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n","4.728516441199087\n"]}]},{"cell_type":"markdown","metadata":{"id":"cZ1D4IWlx9jS"},"source":["## Submit Model 4"]},{"cell_type":"code","metadata":{"id":"ZtUDJdketk7P"},"source":["now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission4_xgb_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_xgb_model.predict(sj_test).astype(int),iq_xgb_model.predict(iq_test).astype(int),name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXb2027vfyd8","executionInfo":{"status":"ok","timestamp":1638471325231,"user_tz":300,"elapsed":6007,"user":{"displayName":"Duncan Ross","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04243431172772025484"}},"outputId":"110c4f43-f637-4777-8635-d5196137482b"},"source":["#For reduced models\n","now = datetime.now()\n","dt_string = now.strftime(\"%d-%m-%Y\")\n","change = input(\"Enter change title: \")\n","name = \"submission4_xgb_\" + change + \"_\" + dt_string\n","\n","createSubmission(sj_xgb_model.predict(reduced_test_sj).astype(int),iq_xgb_model.predict(reduced_test_iq).astype(int),name)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter change title: reduced xgb 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"NMNqw-AwslY8"},"source":["# Random"]},{"cell_type":"code","metadata":{"id":"cdM-LKrSDyNo"},"source":["def testingNew(df):\n","  X = df.copy()\n","  y = X.pop('total_cases')\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.70)\n","  reg_model = make_pipeline(StandardScaler(),SGDRegressor(max_iter=1000, tol=1e-3))\n","  reg_model.fit(X_train, y_train)\n","  predictions = reg_model.predict(X_test)\n","  score = eval_measures.meanabs(predictions, y_test)\n","\n","  return score, reg_model"],"execution_count":null,"outputs":[]}]}